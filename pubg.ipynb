{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pubg1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxGWoWUkWV56",
        "colab_type": "text"
      },
      "source": [
        "##Importing the libraries##"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oif15Ltz5bo1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import log_loss\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import seaborn as sns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L3JZ6hQ3WhKP",
        "colab_type": "text"
      },
      "source": [
        "##**Loading the training data**##"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n14PWJKH5gJ3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = pd.read_csv('train_data.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9mk0JkdKW6Ll",
        "colab_type": "text"
      },
      "source": [
        "##Peek into the dataset##"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQ58-ygU6YBT",
        "colab_type": "code",
        "outputId": "69154b84-d7d2-434a-9070-add270c69d42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Avg_firing_dist</th>\n",
              "      <th>Avg_Srv_time</th>\n",
              "      <th>Avg_ping</th>\n",
              "      <th>Total_travel_dist</th>\n",
              "      <th>Avg_damage</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>264.22</td>\n",
              "      <td>19.06</td>\n",
              "      <td>96.79</td>\n",
              "      <td>6332.00</td>\n",
              "      <td>1788.88</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>366.66</td>\n",
              "      <td>24.42</td>\n",
              "      <td>96.67</td>\n",
              "      <td>6603.70</td>\n",
              "      <td>1750.92</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>259.54</td>\n",
              "      <td>16.37</td>\n",
              "      <td>97.50</td>\n",
              "      <td>6145.80</td>\n",
              "      <td>1838.12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>183.23</td>\n",
              "      <td>13.52</td>\n",
              "      <td>97.31</td>\n",
              "      <td>6584.70</td>\n",
              "      <td>1869.24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>299.71</td>\n",
              "      <td>19.74</td>\n",
              "      <td>97.82</td>\n",
              "      <td>6701.55</td>\n",
              "      <td>1818.88</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Avg_firing_dist  Avg_Srv_time  Avg_ping  Total_travel_dist  Avg_damage\n",
              "0           264.22         19.06     96.79            6332.00     1788.88\n",
              "1           366.66         24.42     96.67            6603.70     1750.92\n",
              "2           259.54         16.37     97.50            6145.80     1838.12\n",
              "3           183.23         13.52     97.31            6584.70     1869.24\n",
              "4           299.71         19.74     97.82            6701.55     1818.88"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t3tp0w4RW-wv",
        "colab_type": "text"
      },
      "source": [
        "##Checking if there exists any NaN value in the dataset##"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88dXawcNU4BE",
        "colab_type": "code",
        "outputId": "ddc0e43e-fbe2-456a-d370-16169a61c6c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "data.isnull().sum()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Avg_firing_dist      0\n",
              "Avg_Srv_time         0\n",
              "Avg_ping             0\n",
              "Total_travel_dist    0\n",
              "Avg_damage           0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82cZCK7yXLd2",
        "colab_type": "text"
      },
      "source": [
        "##Overview of the dataset##"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9ecksx4MPhM",
        "colab_type": "code",
        "outputId": "b7d6be91-69e5-4d6b-df51-843dcb541581",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "source": [
        "data.describe()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Avg_firing_dist</th>\n",
              "      <th>Avg_Srv_time</th>\n",
              "      <th>Avg_ping</th>\n",
              "      <th>Total_travel_dist</th>\n",
              "      <th>Avg_damage</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>2000.000000</td>\n",
              "      <td>2000.000000</td>\n",
              "      <td>2000.000000</td>\n",
              "      <td>2000.000000</td>\n",
              "      <td>2000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>259.133945</td>\n",
              "      <td>16.745235</td>\n",
              "      <td>97.127825</td>\n",
              "      <td>6969.946375</td>\n",
              "      <td>1823.706340</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>97.717665</td>\n",
              "      <td>3.814559</td>\n",
              "      <td>0.540658</td>\n",
              "      <td>1394.220249</td>\n",
              "      <td>69.414587</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>38.540000</td>\n",
              "      <td>8.110000</td>\n",
              "      <td>95.300000</td>\n",
              "      <td>2680.200000</td>\n",
              "      <td>1706.160000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>174.812500</td>\n",
              "      <td>12.960000</td>\n",
              "      <td>96.760000</td>\n",
              "      <td>5976.700000</td>\n",
              "      <td>1764.360000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>268.575000</td>\n",
              "      <td>15.930000</td>\n",
              "      <td>97.090000</td>\n",
              "      <td>7096.750000</td>\n",
              "      <td>1811.980000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>341.375000</td>\n",
              "      <td>20.450000</td>\n",
              "      <td>97.490000</td>\n",
              "      <td>8087.837500</td>\n",
              "      <td>1883.240000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>487.430000</td>\n",
              "      <td>24.420000</td>\n",
              "      <td>98.940000</td>\n",
              "      <td>9520.200000</td>\n",
              "      <td>1988.040000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Avg_firing_dist  Avg_Srv_time     Avg_ping  Total_travel_dist  \\\n",
              "count      2000.000000   2000.000000  2000.000000        2000.000000   \n",
              "mean        259.133945     16.745235    97.127825        6969.946375   \n",
              "std          97.717665      3.814559     0.540658        1394.220249   \n",
              "min          38.540000      8.110000    95.300000        2680.200000   \n",
              "25%         174.812500     12.960000    96.760000        5976.700000   \n",
              "50%         268.575000     15.930000    97.090000        7096.750000   \n",
              "75%         341.375000     20.450000    97.490000        8087.837500   \n",
              "max         487.430000     24.420000    98.940000        9520.200000   \n",
              "\n",
              "        Avg_damage  \n",
              "count  2000.000000  \n",
              "mean   1823.706340  \n",
              "std      69.414587  \n",
              "min    1706.160000  \n",
              "25%    1764.360000  \n",
              "50%    1811.980000  \n",
              "75%    1883.240000  \n",
              "max    1988.040000  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gB2vonYXRVT",
        "colab_type": "text"
      },
      "source": [
        "###Segregating the features from the 'label'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "guz2HNILBKec",
        "colab_type": "code",
        "outputId": "65d46935-3bec-4085-c2a4-74f81f07a34c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "features = list(set(data.columns) - {'Avg_damage'})\n",
        "features"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Avg_ping', 'Total_travel_dist', 'Avg_Srv_time', 'Avg_firing_dist']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dhGa54xiXaeQ",
        "colab_type": "text"
      },
      "source": [
        "##Data Preprocessing\n",
        "\n",
        "Using Standard Scaler to scale the dataset so as to get better performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Ve2uK4VAdcK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scaler = StandardScaler()\n",
        "scaler.fit(data[features])\n",
        "scaled_data = pd.DataFrame(scaler.transform(data[features]))\n",
        "scaled_data.columns = features\n",
        "scaled_data = scaled_data.join(data['Avg_damage'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8jxHb2yCF4P",
        "colab_type": "code",
        "outputId": "738b0ebb-b6b1-4890-df55-8dac2f4b5665",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "scaled_data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Avg_ping</th>\n",
              "      <th>Total_travel_dist</th>\n",
              "      <th>Avg_Srv_time</th>\n",
              "      <th>Avg_firing_dist</th>\n",
              "      <th>Avg_damage</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.624997</td>\n",
              "      <td>-0.457679</td>\n",
              "      <td>0.606975</td>\n",
              "      <td>0.052061</td>\n",
              "      <td>1788.88</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.847004</td>\n",
              "      <td>-0.262755</td>\n",
              "      <td>2.012470</td>\n",
              "      <td>1.100650</td>\n",
              "      <td>1750.92</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.688546</td>\n",
              "      <td>-0.591264</td>\n",
              "      <td>-0.098394</td>\n",
              "      <td>0.004156</td>\n",
              "      <td>1838.12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.337035</td>\n",
              "      <td>-0.276386</td>\n",
              "      <td>-0.845718</td>\n",
              "      <td>-0.776962</td>\n",
              "      <td>1869.24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.280566</td>\n",
              "      <td>-0.192555</td>\n",
              "      <td>0.785284</td>\n",
              "      <td>0.415342</td>\n",
              "      <td>1818.88</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Avg_ping  Total_travel_dist  Avg_Srv_time  Avg_firing_dist  Avg_damage\n",
              "0 -0.624997          -0.457679      0.606975         0.052061     1788.88\n",
              "1 -0.847004          -0.262755      2.012470         1.100650     1750.92\n",
              "2  0.688546          -0.591264     -0.098394         0.004156     1838.12\n",
              "3  0.337035          -0.276386     -0.845718        -0.776962     1869.24\n",
              "4  1.280566          -0.192555      0.785284         0.415342     1818.88"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hjmiBlKPXt1J",
        "colab_type": "text"
      },
      "source": [
        "Scaling the 'label' as well by a factor of 1000."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8aBPX_WCKI4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scaled_data['Avg_damage'] = scaled_data['Avg_damage']/1000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nd1O1IbiCWwp",
        "colab_type": "code",
        "outputId": "54f51851-e7a7-44d7-cae0-b0ff94b99495",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "scaled_data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Avg_ping</th>\n",
              "      <th>Total_travel_dist</th>\n",
              "      <th>Avg_Srv_time</th>\n",
              "      <th>Avg_firing_dist</th>\n",
              "      <th>Avg_damage</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.624997</td>\n",
              "      <td>-0.457679</td>\n",
              "      <td>0.606975</td>\n",
              "      <td>0.052061</td>\n",
              "      <td>1.78888</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.847004</td>\n",
              "      <td>-0.262755</td>\n",
              "      <td>2.012470</td>\n",
              "      <td>1.100650</td>\n",
              "      <td>1.75092</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.688546</td>\n",
              "      <td>-0.591264</td>\n",
              "      <td>-0.098394</td>\n",
              "      <td>0.004156</td>\n",
              "      <td>1.83812</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.337035</td>\n",
              "      <td>-0.276386</td>\n",
              "      <td>-0.845718</td>\n",
              "      <td>-0.776962</td>\n",
              "      <td>1.86924</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.280566</td>\n",
              "      <td>-0.192555</td>\n",
              "      <td>0.785284</td>\n",
              "      <td>0.415342</td>\n",
              "      <td>1.81888</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Avg_ping  Total_travel_dist  Avg_Srv_time  Avg_firing_dist  Avg_damage\n",
              "0 -0.624997          -0.457679      0.606975         0.052061     1.78888\n",
              "1 -0.847004          -0.262755      2.012470         1.100650     1.75092\n",
              "2  0.688546          -0.591264     -0.098394         0.004156     1.83812\n",
              "3  0.337035          -0.276386     -0.845718        -0.776962     1.86924\n",
              "4  1.280566          -0.192555      0.785284         0.415342     1.81888"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_IpCAyX6X5Mb",
        "colab_type": "text"
      },
      "source": [
        "##Setting up the Neural Network for predicting the Average Damage"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CA2dFLTnYHF-",
        "colab_type": "text"
      },
      "source": [
        "###Importing Keras libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZbiAkrh2Cb1Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers.core import Dense, Activation\n",
        "from keras.models import Sequential\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import np_utils"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0EDY5sUzYUTd",
        "colab_type": "text"
      },
      "source": [
        "###Defining the model\n",
        "\n",
        "Using the 'ReLU - Rectified Linear Unit' and 'Linear' activation functions.\n",
        "\n",
        "The model will be like :  relu() --> linear()\n",
        "\n",
        "Also, will be using the Mean Squared Error loss function and RMSProp() optimizer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWp3gQzUDLRq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def nn_model(input_dim):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(10, input_dim=input_dim))\n",
        "    model.add(Activation('relu'))\n",
        "    \n",
        "    model.add(Dense(1))\n",
        "    model.add(Activation('linear'))\n",
        "\n",
        "    model.compile(loss='mean_absolute_error', optimizer=Adam())\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_r9FXmwZIxp",
        "colab_type": "text"
      },
      "source": [
        "###Training the model\n",
        "\n",
        "Training the model with the features and label by passing a batch of size 256 at a time, which goes on for 1000 iterations.\n",
        "Also, creating a Validation set with 20% data so as to prevent overfitting of data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAl2DTruDfnb",
        "colab_type": "code",
        "outputId": "9a2aa79b-c8b6-4279-f75f-84142ed9c827",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34051
        }
      },
      "source": [
        "nn = nn_model(len(features))\n",
        "nn.fit(scaled_data[features], scaled_data['Avg_damage'], verbose=1, validation_split = 0.2, epochs=1000, batch_size=256)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1600 samples, validate on 400 samples\n",
            "Epoch 1/1000\n",
            "1600/1600 [==============================] - 1s 507us/step - loss: 2.0724 - val_loss: 2.0209\n",
            "Epoch 2/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 2.0115 - val_loss: 1.9596\n",
            "Epoch 3/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 1.9488 - val_loss: 1.8987\n",
            "Epoch 4/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 1.8876 - val_loss: 1.8387\n",
            "Epoch 5/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 1.8268 - val_loss: 1.7803\n",
            "Epoch 6/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 1.7682 - val_loss: 1.7221\n",
            "Epoch 7/1000\n",
            "1600/1600 [==============================] - 0s 11us/step - loss: 1.7099 - val_loss: 1.6649\n",
            "Epoch 8/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 1.6529 - val_loss: 1.6082\n",
            "Epoch 9/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 1.5957 - val_loss: 1.5521\n",
            "Epoch 10/1000\n",
            "1600/1600 [==============================] - 0s 11us/step - loss: 1.5395 - val_loss: 1.4973\n",
            "Epoch 11/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 1.4862 - val_loss: 1.4447\n",
            "Epoch 12/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 1.4352 - val_loss: 1.3945\n",
            "Epoch 13/1000\n",
            "1600/1600 [==============================] - 0s 12us/step - loss: 1.3876 - val_loss: 1.3511\n",
            "Epoch 14/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 1.3461 - val_loss: 1.3123\n",
            "Epoch 15/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 1.3092 - val_loss: 1.2767\n",
            "Epoch 16/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 1.2753 - val_loss: 1.2458\n",
            "Epoch 17/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 1.2454 - val_loss: 1.2183\n",
            "Epoch 18/1000\n",
            "1600/1600 [==============================] - 0s 11us/step - loss: 1.2180 - val_loss: 1.1924\n",
            "Epoch 19/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 1.1918 - val_loss: 1.1676\n",
            "Epoch 20/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 1.1664 - val_loss: 1.1437\n",
            "Epoch 21/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 1.1415 - val_loss: 1.1206\n",
            "Epoch 22/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 1.1172 - val_loss: 1.0976\n",
            "Epoch 23/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 1.0934 - val_loss: 1.0748\n",
            "Epoch 24/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 1.0693 - val_loss: 1.0523\n",
            "Epoch 25/1000\n",
            "1600/1600 [==============================] - 0s 11us/step - loss: 1.0456 - val_loss: 1.0298\n",
            "Epoch 26/1000\n",
            "1600/1600 [==============================] - 0s 11us/step - loss: 1.0218 - val_loss: 1.0072\n",
            "Epoch 27/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.9975 - val_loss: 0.9837\n",
            "Epoch 28/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.9731 - val_loss: 0.9592\n",
            "Epoch 29/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.9478 - val_loss: 0.9340\n",
            "Epoch 30/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.9222 - val_loss: 0.9081\n",
            "Epoch 31/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.8956 - val_loss: 0.8814\n",
            "Epoch 32/1000\n",
            "1600/1600 [==============================] - 0s 11us/step - loss: 0.8677 - val_loss: 0.8542\n",
            "Epoch 33/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.8393 - val_loss: 0.8265\n",
            "Epoch 34/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.8099 - val_loss: 0.7988\n",
            "Epoch 35/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.7803 - val_loss: 0.7708\n",
            "Epoch 36/1000\n",
            "1600/1600 [==============================] - 0s 12us/step - loss: 0.7503 - val_loss: 0.7445\n",
            "Epoch 37/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.7215 - val_loss: 0.7184\n",
            "Epoch 38/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.6918 - val_loss: 0.6918\n",
            "Epoch 39/1000\n",
            "1600/1600 [==============================] - 0s 11us/step - loss: 0.6624 - val_loss: 0.6639\n",
            "Epoch 40/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.6327 - val_loss: 0.6346\n",
            "Epoch 41/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.6033 - val_loss: 0.6050\n",
            "Epoch 42/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.5745 - val_loss: 0.5760\n",
            "Epoch 43/1000\n",
            "1600/1600 [==============================] - 0s 8us/step - loss: 0.5459 - val_loss: 0.5471\n",
            "Epoch 44/1000\n",
            "1600/1600 [==============================] - 0s 11us/step - loss: 0.5173 - val_loss: 0.5186\n",
            "Epoch 45/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.4903 - val_loss: 0.4906\n",
            "Epoch 46/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.4637 - val_loss: 0.4632\n",
            "Epoch 47/1000\n",
            "1600/1600 [==============================] - 0s 11us/step - loss: 0.4388 - val_loss: 0.4383\n",
            "Epoch 48/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.4150 - val_loss: 0.4145\n",
            "Epoch 49/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.3930 - val_loss: 0.3925\n",
            "Epoch 50/1000\n",
            "1600/1600 [==============================] - 0s 11us/step - loss: 0.3721 - val_loss: 0.3722\n",
            "Epoch 51/1000\n",
            "1600/1600 [==============================] - 0s 11us/step - loss: 0.3531 - val_loss: 0.3531\n",
            "Epoch 52/1000\n",
            "1600/1600 [==============================] - 0s 11us/step - loss: 0.3356 - val_loss: 0.3357\n",
            "Epoch 53/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.3196 - val_loss: 0.3197\n",
            "Epoch 54/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.3047 - val_loss: 0.3052\n",
            "Epoch 55/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.2918 - val_loss: 0.2918\n",
            "Epoch 56/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.2800 - val_loss: 0.2797\n",
            "Epoch 57/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.2690 - val_loss: 0.2692\n",
            "Epoch 58/1000\n",
            "1600/1600 [==============================] - 0s 12us/step - loss: 0.2589 - val_loss: 0.2594\n",
            "Epoch 59/1000\n",
            "1600/1600 [==============================] - 0s 11us/step - loss: 0.2497 - val_loss: 0.2510\n",
            "Epoch 60/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.2412 - val_loss: 0.2431\n",
            "Epoch 61/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.2336 - val_loss: 0.2354\n",
            "Epoch 62/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.2265 - val_loss: 0.2284\n",
            "Epoch 63/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.2200 - val_loss: 0.2219\n",
            "Epoch 64/1000\n",
            "1600/1600 [==============================] - 0s 11us/step - loss: 0.2139 - val_loss: 0.2157\n",
            "Epoch 65/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.2080 - val_loss: 0.2097\n",
            "Epoch 66/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.2022 - val_loss: 0.2038\n",
            "Epoch 67/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.1965 - val_loss: 0.1981\n",
            "Epoch 68/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.1910 - val_loss: 0.1926\n",
            "Epoch 69/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.1856 - val_loss: 0.1873\n",
            "Epoch 70/1000\n",
            "1600/1600 [==============================] - 0s 12us/step - loss: 0.1805 - val_loss: 0.1822\n",
            "Epoch 71/1000\n",
            "1600/1600 [==============================] - 0s 11us/step - loss: 0.1753 - val_loss: 0.1765\n",
            "Epoch 72/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.1705 - val_loss: 0.1716\n",
            "Epoch 73/1000\n",
            "1600/1600 [==============================] - 0s 11us/step - loss: 0.1659 - val_loss: 0.1671\n",
            "Epoch 74/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.1616 - val_loss: 0.1628\n",
            "Epoch 75/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.1577 - val_loss: 0.1583\n",
            "Epoch 76/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.1538 - val_loss: 0.1542\n",
            "Epoch 77/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.1501 - val_loss: 0.1502\n",
            "Epoch 78/1000\n",
            "1600/1600 [==============================] - 0s 13us/step - loss: 0.1463 - val_loss: 0.1460\n",
            "Epoch 79/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.1427 - val_loss: 0.1425\n",
            "Epoch 80/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.1392 - val_loss: 0.1385\n",
            "Epoch 81/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.1358 - val_loss: 0.1350\n",
            "Epoch 82/1000\n",
            "1600/1600 [==============================] - 0s 14us/step - loss: 0.1326 - val_loss: 0.1321\n",
            "Epoch 83/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.1297 - val_loss: 0.1291\n",
            "Epoch 84/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.1270 - val_loss: 0.1270\n",
            "Epoch 85/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.1243 - val_loss: 0.1243\n",
            "Epoch 86/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.1218 - val_loss: 0.1218\n",
            "Epoch 87/1000\n",
            "1600/1600 [==============================] - 0s 11us/step - loss: 0.1193 - val_loss: 0.1197\n",
            "Epoch 88/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.1168 - val_loss: 0.1176\n",
            "Epoch 89/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.1143 - val_loss: 0.1149\n",
            "Epoch 90/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.1121 - val_loss: 0.1126\n",
            "Epoch 91/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.1097 - val_loss: 0.1102\n",
            "Epoch 92/1000\n",
            "1600/1600 [==============================] - 0s 15us/step - loss: 0.1074 - val_loss: 0.1082\n",
            "Epoch 93/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.1051 - val_loss: 0.1057\n",
            "Epoch 94/1000\n",
            "1600/1600 [==============================] - 0s 11us/step - loss: 0.1026 - val_loss: 0.1038\n",
            "Epoch 95/1000\n",
            "1600/1600 [==============================] - 0s 11us/step - loss: 0.1005 - val_loss: 0.1017\n",
            "Epoch 96/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0984 - val_loss: 0.0996\n",
            "Epoch 97/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0963 - val_loss: 0.0974\n",
            "Epoch 98/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0944 - val_loss: 0.0960\n",
            "Epoch 99/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0926 - val_loss: 0.0939\n",
            "Epoch 100/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0908 - val_loss: 0.0925\n",
            "Epoch 101/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0891 - val_loss: 0.0905\n",
            "Epoch 102/1000\n",
            "1600/1600 [==============================] - 0s 11us/step - loss: 0.0876 - val_loss: 0.0890\n",
            "Epoch 103/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0861 - val_loss: 0.0874\n",
            "Epoch 104/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0843 - val_loss: 0.0859\n",
            "Epoch 105/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0828 - val_loss: 0.0843\n",
            "Epoch 106/1000\n",
            "1600/1600 [==============================] - 0s 11us/step - loss: 0.0812 - val_loss: 0.0828\n",
            "Epoch 107/1000\n",
            "1600/1600 [==============================] - 0s 11us/step - loss: 0.0798 - val_loss: 0.0814\n",
            "Epoch 108/1000\n",
            "1600/1600 [==============================] - 0s 13us/step - loss: 0.0783 - val_loss: 0.0800\n",
            "Epoch 109/1000\n",
            "1600/1600 [==============================] - 0s 11us/step - loss: 0.0769 - val_loss: 0.0788\n",
            "Epoch 110/1000\n",
            "1600/1600 [==============================] - 0s 12us/step - loss: 0.0755 - val_loss: 0.0774\n",
            "Epoch 111/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0741 - val_loss: 0.0758\n",
            "Epoch 112/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0727 - val_loss: 0.0743\n",
            "Epoch 113/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0715 - val_loss: 0.0732\n",
            "Epoch 114/1000\n",
            "1600/1600 [==============================] - 0s 11us/step - loss: 0.0702 - val_loss: 0.0718\n",
            "Epoch 115/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0688 - val_loss: 0.0704\n",
            "Epoch 116/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0676 - val_loss: 0.0690\n",
            "Epoch 117/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0665 - val_loss: 0.0678\n",
            "Epoch 118/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0653 - val_loss: 0.0665\n",
            "Epoch 119/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0639 - val_loss: 0.0659\n",
            "Epoch 120/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0628 - val_loss: 0.0638\n",
            "Epoch 121/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0613 - val_loss: 0.0625\n",
            "Epoch 122/1000\n",
            "1600/1600 [==============================] - 0s 11us/step - loss: 0.0599 - val_loss: 0.0612\n",
            "Epoch 123/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0586 - val_loss: 0.0600\n",
            "Epoch 124/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0574 - val_loss: 0.0586\n",
            "Epoch 125/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0564 - val_loss: 0.0574\n",
            "Epoch 126/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0549 - val_loss: 0.0562\n",
            "Epoch 127/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0536 - val_loss: 0.0548\n",
            "Epoch 128/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0520 - val_loss: 0.0536\n",
            "Epoch 129/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0509 - val_loss: 0.0525\n",
            "Epoch 130/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0495 - val_loss: 0.0508\n",
            "Epoch 131/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0482 - val_loss: 0.0495\n",
            "Epoch 132/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0468 - val_loss: 0.0476\n",
            "Epoch 133/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0454 - val_loss: 0.0463\n",
            "Epoch 134/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0441 - val_loss: 0.0453\n",
            "Epoch 135/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0429 - val_loss: 0.0440\n",
            "Epoch 136/1000\n",
            "1600/1600 [==============================] - 0s 8us/step - loss: 0.0417 - val_loss: 0.0425\n",
            "Epoch 137/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0406 - val_loss: 0.0413\n",
            "Epoch 138/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0394 - val_loss: 0.0401\n",
            "Epoch 139/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0382 - val_loss: 0.0390\n",
            "Epoch 140/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0372 - val_loss: 0.0378\n",
            "Epoch 141/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0360 - val_loss: 0.0368\n",
            "Epoch 142/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0350 - val_loss: 0.0356\n",
            "Epoch 143/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0338 - val_loss: 0.0345\n",
            "Epoch 144/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0329 - val_loss: 0.0334\n",
            "Epoch 145/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0318 - val_loss: 0.0322\n",
            "Epoch 146/1000\n",
            "1600/1600 [==============================] - 0s 11us/step - loss: 0.0308 - val_loss: 0.0314\n",
            "Epoch 147/1000\n",
            "1600/1600 [==============================] - 0s 14us/step - loss: 0.0299 - val_loss: 0.0305\n",
            "Epoch 148/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0291 - val_loss: 0.0296\n",
            "Epoch 149/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0284 - val_loss: 0.0291\n",
            "Epoch 150/1000\n",
            "1600/1600 [==============================] - 0s 12us/step - loss: 0.0276 - val_loss: 0.0284\n",
            "Epoch 151/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0270 - val_loss: 0.0282\n",
            "Epoch 152/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0265 - val_loss: 0.0277\n",
            "Epoch 153/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0259 - val_loss: 0.0271\n",
            "Epoch 154/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0254 - val_loss: 0.0265\n",
            "Epoch 155/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0249 - val_loss: 0.0260\n",
            "Epoch 156/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0246 - val_loss: 0.0257\n",
            "Epoch 157/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0242 - val_loss: 0.0250\n",
            "Epoch 158/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0236 - val_loss: 0.0251\n",
            "Epoch 159/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0235 - val_loss: 0.0249\n",
            "Epoch 160/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0231 - val_loss: 0.0246\n",
            "Epoch 161/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0228 - val_loss: 0.0249\n",
            "Epoch 162/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0224 - val_loss: 0.0238\n",
            "Epoch 163/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0223 - val_loss: 0.0247\n",
            "Epoch 164/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0220 - val_loss: 0.0236\n",
            "Epoch 165/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0215 - val_loss: 0.0234\n",
            "Epoch 166/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0212 - val_loss: 0.0232\n",
            "Epoch 167/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0209 - val_loss: 0.0233\n",
            "Epoch 168/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0208 - val_loss: 0.0231\n",
            "Epoch 169/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0208 - val_loss: 0.0227\n",
            "Epoch 170/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0207 - val_loss: 0.0227\n",
            "Epoch 171/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0205 - val_loss: 0.0230\n",
            "Epoch 172/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0201 - val_loss: 0.0225\n",
            "Epoch 173/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0199 - val_loss: 0.0223\n",
            "Epoch 174/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0197 - val_loss: 0.0222\n",
            "Epoch 175/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0196 - val_loss: 0.0220\n",
            "Epoch 176/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0194 - val_loss: 0.0218\n",
            "Epoch 177/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0193 - val_loss: 0.0217\n",
            "Epoch 178/1000\n",
            "1600/1600 [==============================] - 0s 8us/step - loss: 0.0191 - val_loss: 0.0219\n",
            "Epoch 179/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0191 - val_loss: 0.0216\n",
            "Epoch 180/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0190 - val_loss: 0.0215\n",
            "Epoch 181/1000\n",
            "1600/1600 [==============================] - 0s 12us/step - loss: 0.0189 - val_loss: 0.0217\n",
            "Epoch 182/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0189 - val_loss: 0.0214\n",
            "Epoch 183/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0187 - val_loss: 0.0213\n",
            "Epoch 184/1000\n",
            "1600/1600 [==============================] - 0s 11us/step - loss: 0.0187 - val_loss: 0.0209\n",
            "Epoch 185/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0187 - val_loss: 0.0211\n",
            "Epoch 186/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0185 - val_loss: 0.0215\n",
            "Epoch 187/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0186 - val_loss: 0.0209\n",
            "Epoch 188/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0183 - val_loss: 0.0207\n",
            "Epoch 189/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0182 - val_loss: 0.0209\n",
            "Epoch 190/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0180 - val_loss: 0.0215\n",
            "Epoch 191/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0185 - val_loss: 0.0204\n",
            "Epoch 192/1000\n",
            "1600/1600 [==============================] - 0s 11us/step - loss: 0.0180 - val_loss: 0.0203\n",
            "Epoch 193/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0177 - val_loss: 0.0203\n",
            "Epoch 194/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0177 - val_loss: 0.0201\n",
            "Epoch 195/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0177 - val_loss: 0.0205\n",
            "Epoch 196/1000\n",
            "1600/1600 [==============================] - 0s 8us/step - loss: 0.0178 - val_loss: 0.0201\n",
            "Epoch 197/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0175 - val_loss: 0.0199\n",
            "Epoch 198/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0175 - val_loss: 0.0197\n",
            "Epoch 199/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0173 - val_loss: 0.0199\n",
            "Epoch 200/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0172 - val_loss: 0.0195\n",
            "Epoch 201/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0171 - val_loss: 0.0196\n",
            "Epoch 202/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0172 - val_loss: 0.0198\n",
            "Epoch 203/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0170 - val_loss: 0.0193\n",
            "Epoch 204/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0169 - val_loss: 0.0195\n",
            "Epoch 205/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0173 - val_loss: 0.0194\n",
            "Epoch 206/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0171 - val_loss: 0.0204\n",
            "Epoch 207/1000\n",
            "1600/1600 [==============================] - 0s 11us/step - loss: 0.0172 - val_loss: 0.0190\n",
            "Epoch 208/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0168 - val_loss: 0.0191\n",
            "Epoch 209/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0169 - val_loss: 0.0191\n",
            "Epoch 210/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0167 - val_loss: 0.0189\n",
            "Epoch 211/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0167 - val_loss: 0.0190\n",
            "Epoch 212/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0165 - val_loss: 0.0192\n",
            "Epoch 213/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0166 - val_loss: 0.0188\n",
            "Epoch 214/1000\n",
            "1600/1600 [==============================] - 0s 11us/step - loss: 0.0165 - val_loss: 0.0186\n",
            "Epoch 215/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0164 - val_loss: 0.0188\n",
            "Epoch 216/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0164 - val_loss: 0.0189\n",
            "Epoch 217/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0164 - val_loss: 0.0185\n",
            "Epoch 218/1000\n",
            "1600/1600 [==============================] - 0s 11us/step - loss: 0.0163 - val_loss: 0.0187\n",
            "Epoch 219/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0163 - val_loss: 0.0188\n",
            "Epoch 220/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0163 - val_loss: 0.0188\n",
            "Epoch 221/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0163 - val_loss: 0.0186\n",
            "Epoch 222/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0162 - val_loss: 0.0184\n",
            "Epoch 223/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0161 - val_loss: 0.0182\n",
            "Epoch 224/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0161 - val_loss: 0.0180\n",
            "Epoch 225/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0158 - val_loss: 0.0182\n",
            "Epoch 226/1000\n",
            "1600/1600 [==============================] - 0s 12us/step - loss: 0.0159 - val_loss: 0.0181\n",
            "Epoch 227/1000\n",
            "1600/1600 [==============================] - 0s 12us/step - loss: 0.0159 - val_loss: 0.0179\n",
            "Epoch 228/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0158 - val_loss: 0.0181\n",
            "Epoch 229/1000\n",
            "1600/1600 [==============================] - 0s 11us/step - loss: 0.0157 - val_loss: 0.0179\n",
            "Epoch 230/1000\n",
            "1600/1600 [==============================] - 0s 11us/step - loss: 0.0158 - val_loss: 0.0182\n",
            "Epoch 231/1000\n",
            "1600/1600 [==============================] - 0s 14us/step - loss: 0.0157 - val_loss: 0.0181\n",
            "Epoch 232/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0159 - val_loss: 0.0181\n",
            "Epoch 233/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0160 - val_loss: 0.0178\n",
            "Epoch 234/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0159 - val_loss: 0.0175\n",
            "Epoch 235/1000\n",
            "1600/1600 [==============================] - 0s 8us/step - loss: 0.0154 - val_loss: 0.0179\n",
            "Epoch 236/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0156 - val_loss: 0.0177\n",
            "Epoch 237/1000\n",
            "1600/1600 [==============================] - 0s 8us/step - loss: 0.0154 - val_loss: 0.0174\n",
            "Epoch 238/1000\n",
            "1600/1600 [==============================] - 0s 12us/step - loss: 0.0155 - val_loss: 0.0175\n",
            "Epoch 239/1000\n",
            "1600/1600 [==============================] - 0s 11us/step - loss: 0.0153 - val_loss: 0.0174\n",
            "Epoch 240/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0155 - val_loss: 0.0173\n",
            "Epoch 241/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0153 - val_loss: 0.0173\n",
            "Epoch 242/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0152 - val_loss: 0.0172\n",
            "Epoch 243/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0151 - val_loss: 0.0173\n",
            "Epoch 244/1000\n",
            "1600/1600 [==============================] - 0s 11us/step - loss: 0.0151 - val_loss: 0.0171\n",
            "Epoch 245/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0150 - val_loss: 0.0173\n",
            "Epoch 246/1000\n",
            "1600/1600 [==============================] - 0s 11us/step - loss: 0.0151 - val_loss: 0.0171\n",
            "Epoch 247/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0151 - val_loss: 0.0178\n",
            "Epoch 248/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0152 - val_loss: 0.0173\n",
            "Epoch 249/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0150 - val_loss: 0.0170\n",
            "Epoch 250/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0150 - val_loss: 0.0171\n",
            "Epoch 251/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0149 - val_loss: 0.0171\n",
            "Epoch 252/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0150 - val_loss: 0.0171\n",
            "Epoch 253/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0148 - val_loss: 0.0168\n",
            "Epoch 254/1000\n",
            "1600/1600 [==============================] - 0s 11us/step - loss: 0.0149 - val_loss: 0.0169\n",
            "Epoch 255/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0149 - val_loss: 0.0169\n",
            "Epoch 256/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0148 - val_loss: 0.0168\n",
            "Epoch 257/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0149 - val_loss: 0.0169\n",
            "Epoch 258/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0150 - val_loss: 0.0167\n",
            "Epoch 259/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0148 - val_loss: 0.0168\n",
            "Epoch 260/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0148 - val_loss: 0.0170\n",
            "Epoch 261/1000\n",
            "1600/1600 [==============================] - 0s 11us/step - loss: 0.0149 - val_loss: 0.0168\n",
            "Epoch 262/1000\n",
            "1600/1600 [==============================] - 0s 14us/step - loss: 0.0147 - val_loss: 0.0165\n",
            "Epoch 263/1000\n",
            "1600/1600 [==============================] - 0s 11us/step - loss: 0.0146 - val_loss: 0.0166\n",
            "Epoch 264/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0146 - val_loss: 0.0164\n",
            "Epoch 265/1000\n",
            "1600/1600 [==============================] - 0s 11us/step - loss: 0.0145 - val_loss: 0.0167\n",
            "Epoch 266/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0146 - val_loss: 0.0165\n",
            "Epoch 267/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0146 - val_loss: 0.0167\n",
            "Epoch 268/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0147 - val_loss: 0.0166\n",
            "Epoch 269/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0146 - val_loss: 0.0164\n",
            "Epoch 270/1000\n",
            "1600/1600 [==============================] - 0s 12us/step - loss: 0.0146 - val_loss: 0.0162\n",
            "Epoch 271/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0145 - val_loss: 0.0163\n",
            "Epoch 272/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0145 - val_loss: 0.0164\n",
            "Epoch 273/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0145 - val_loss: 0.0161\n",
            "Epoch 274/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0145 - val_loss: 0.0162\n",
            "Epoch 275/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0144 - val_loss: 0.0164\n",
            "Epoch 276/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0145 - val_loss: 0.0164\n",
            "Epoch 277/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0146 - val_loss: 0.0163\n",
            "Epoch 278/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0147 - val_loss: 0.0161\n",
            "Epoch 279/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0148 - val_loss: 0.0163\n",
            "Epoch 280/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0144 - val_loss: 0.0162\n",
            "Epoch 281/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0144 - val_loss: 0.0160\n",
            "Epoch 282/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0147 - val_loss: 0.0161\n",
            "Epoch 283/1000\n",
            "1600/1600 [==============================] - 0s 13us/step - loss: 0.0146 - val_loss: 0.0161\n",
            "Epoch 284/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0146 - val_loss: 0.0160\n",
            "Epoch 285/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0142 - val_loss: 0.0160\n",
            "Epoch 286/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0143 - val_loss: 0.0164\n",
            "Epoch 287/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0145 - val_loss: 0.0158\n",
            "Epoch 288/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0143 - val_loss: 0.0157\n",
            "Epoch 289/1000\n",
            "1600/1600 [==============================] - 0s 11us/step - loss: 0.0143 - val_loss: 0.0161\n",
            "Epoch 290/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0142 - val_loss: 0.0158\n",
            "Epoch 291/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0142 - val_loss: 0.0159\n",
            "Epoch 292/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0141 - val_loss: 0.0157\n",
            "Epoch 293/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0141 - val_loss: 0.0157\n",
            "Epoch 294/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0145 - val_loss: 0.0161\n",
            "Epoch 295/1000\n",
            "1600/1600 [==============================] - 0s 13us/step - loss: 0.0146 - val_loss: 0.0161\n",
            "Epoch 296/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0142 - val_loss: 0.0154\n",
            "Epoch 297/1000\n",
            "1600/1600 [==============================] - 0s 8us/step - loss: 0.0141 - val_loss: 0.0157\n",
            "Epoch 298/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0141 - val_loss: 0.0155\n",
            "Epoch 299/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0141 - val_loss: 0.0157\n",
            "Epoch 300/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0141 - val_loss: 0.0155\n",
            "Epoch 301/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0141 - val_loss: 0.0156\n",
            "Epoch 302/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0141 - val_loss: 0.0162\n",
            "Epoch 303/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0146 - val_loss: 0.0156\n",
            "Epoch 304/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0143 - val_loss: 0.0155\n",
            "Epoch 305/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0142 - val_loss: 0.0158\n",
            "Epoch 306/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0142 - val_loss: 0.0153\n",
            "Epoch 307/1000\n",
            "1600/1600 [==============================] - 0s 8us/step - loss: 0.0142 - val_loss: 0.0155\n",
            "Epoch 308/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0141 - val_loss: 0.0156\n",
            "Epoch 309/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0140 - val_loss: 0.0155\n",
            "Epoch 310/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0140 - val_loss: 0.0154\n",
            "Epoch 311/1000\n",
            "1600/1600 [==============================] - 0s 13us/step - loss: 0.0143 - val_loss: 0.0155\n",
            "Epoch 312/1000\n",
            "1600/1600 [==============================] - 0s 12us/step - loss: 0.0143 - val_loss: 0.0159\n",
            "Epoch 313/1000\n",
            "1600/1600 [==============================] - 0s 8us/step - loss: 0.0141 - val_loss: 0.0153\n",
            "Epoch 314/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0140 - val_loss: 0.0153\n",
            "Epoch 315/1000\n",
            "1600/1600 [==============================] - 0s 11us/step - loss: 0.0139 - val_loss: 0.0153\n",
            "Epoch 316/1000\n",
            "1600/1600 [==============================] - 0s 11us/step - loss: 0.0140 - val_loss: 0.0151\n",
            "Epoch 317/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0140 - val_loss: 0.0156\n",
            "Epoch 318/1000\n",
            "1600/1600 [==============================] - 0s 11us/step - loss: 0.0140 - val_loss: 0.0151\n",
            "Epoch 319/1000\n",
            "1600/1600 [==============================] - 0s 12us/step - loss: 0.0139 - val_loss: 0.0154\n",
            "Epoch 320/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0139 - val_loss: 0.0153\n",
            "Epoch 321/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0141 - val_loss: 0.0153\n",
            "Epoch 322/1000\n",
            "1600/1600 [==============================] - 0s 14us/step - loss: 0.0142 - val_loss: 0.0151\n",
            "Epoch 323/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0141 - val_loss: 0.0153\n",
            "Epoch 324/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0140 - val_loss: 0.0154\n",
            "Epoch 325/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0141 - val_loss: 0.0153\n",
            "Epoch 326/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0139 - val_loss: 0.0154\n",
            "Epoch 327/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0141 - val_loss: 0.0153\n",
            "Epoch 328/1000\n",
            "1600/1600 [==============================] - 0s 11us/step - loss: 0.0141 - val_loss: 0.0151\n",
            "Epoch 329/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0138 - val_loss: 0.0154\n",
            "Epoch 330/1000\n",
            "1600/1600 [==============================] - 0s 12us/step - loss: 0.0144 - val_loss: 0.0155\n",
            "Epoch 331/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0146 - val_loss: 0.0166\n",
            "Epoch 332/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0145 - val_loss: 0.0150\n",
            "Epoch 333/1000\n",
            "1600/1600 [==============================] - 0s 11us/step - loss: 0.0141 - val_loss: 0.0151\n",
            "Epoch 334/1000\n",
            "1600/1600 [==============================] - 0s 13us/step - loss: 0.0140 - val_loss: 0.0150\n",
            "Epoch 335/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0139 - val_loss: 0.0152\n",
            "Epoch 336/1000\n",
            "1600/1600 [==============================] - 0s 8us/step - loss: 0.0138 - val_loss: 0.0151\n",
            "Epoch 337/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0139 - val_loss: 0.0149\n",
            "Epoch 338/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0137 - val_loss: 0.0151\n",
            "Epoch 339/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0137 - val_loss: 0.0150\n",
            "Epoch 340/1000\n",
            "1600/1600 [==============================] - 0s 8us/step - loss: 0.0139 - val_loss: 0.0153\n",
            "Epoch 341/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0141 - val_loss: 0.0150\n",
            "Epoch 342/1000\n",
            "1600/1600 [==============================] - 0s 12us/step - loss: 0.0139 - val_loss: 0.0151\n",
            "Epoch 343/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0139 - val_loss: 0.0149\n",
            "Epoch 344/1000\n",
            "1600/1600 [==============================] - 0s 11us/step - loss: 0.0140 - val_loss: 0.0149\n",
            "Epoch 345/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0137 - val_loss: 0.0153\n",
            "Epoch 346/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0138 - val_loss: 0.0148\n",
            "Epoch 347/1000\n",
            "1600/1600 [==============================] - 0s 8us/step - loss: 0.0139 - val_loss: 0.0153\n",
            "Epoch 348/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0140 - val_loss: 0.0149\n",
            "Epoch 349/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0140 - val_loss: 0.0157\n",
            "Epoch 350/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0140 - val_loss: 0.0148\n",
            "Epoch 351/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0137 - val_loss: 0.0148\n",
            "Epoch 352/1000\n",
            "1600/1600 [==============================] - 0s 11us/step - loss: 0.0138 - val_loss: 0.0148\n",
            "Epoch 353/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0138 - val_loss: 0.0148\n",
            "Epoch 354/1000\n",
            "1600/1600 [==============================] - 0s 13us/step - loss: 0.0140 - val_loss: 0.0152\n",
            "Epoch 355/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0140 - val_loss: 0.0149\n",
            "Epoch 356/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0138 - val_loss: 0.0149\n",
            "Epoch 357/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0138 - val_loss: 0.0149\n",
            "Epoch 358/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0137 - val_loss: 0.0149\n",
            "Epoch 359/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0137 - val_loss: 0.0148\n",
            "Epoch 360/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0138 - val_loss: 0.0152\n",
            "Epoch 361/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0138 - val_loss: 0.0148\n",
            "Epoch 362/1000\n",
            "1600/1600 [==============================] - 0s 8us/step - loss: 0.0137 - val_loss: 0.0157\n",
            "Epoch 363/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0140 - val_loss: 0.0148\n",
            "Epoch 364/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0139 - val_loss: 0.0145\n",
            "Epoch 365/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0137 - val_loss: 0.0150\n",
            "Epoch 366/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0137 - val_loss: 0.0149\n",
            "Epoch 367/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0138 - val_loss: 0.0147\n",
            "Epoch 368/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0137 - val_loss: 0.0148\n",
            "Epoch 369/1000\n",
            "1600/1600 [==============================] - 0s 12us/step - loss: 0.0139 - val_loss: 0.0147\n",
            "Epoch 370/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0136 - val_loss: 0.0149\n",
            "Epoch 371/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0136 - val_loss: 0.0146\n",
            "Epoch 372/1000\n",
            "1600/1600 [==============================] - 0s 8us/step - loss: 0.0137 - val_loss: 0.0150\n",
            "Epoch 373/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0139 - val_loss: 0.0146\n",
            "Epoch 374/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0136 - val_loss: 0.0147\n",
            "Epoch 375/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0137 - val_loss: 0.0147\n",
            "Epoch 376/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0136 - val_loss: 0.0151\n",
            "Epoch 377/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0139 - val_loss: 0.0145\n",
            "Epoch 378/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0139 - val_loss: 0.0147\n",
            "Epoch 379/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0138 - val_loss: 0.0146\n",
            "Epoch 380/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0135 - val_loss: 0.0145\n",
            "Epoch 381/1000\n",
            "1600/1600 [==============================] - 0s 8us/step - loss: 0.0135 - val_loss: 0.0146\n",
            "Epoch 382/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0136 - val_loss: 0.0157\n",
            "Epoch 383/1000\n",
            "1600/1600 [==============================] - 0s 11us/step - loss: 0.0139 - val_loss: 0.0148\n",
            "Epoch 384/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0141 - val_loss: 0.0148\n",
            "Epoch 385/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0139 - val_loss: 0.0146\n",
            "Epoch 386/1000\n",
            "1600/1600 [==============================] - 0s 11us/step - loss: 0.0136 - val_loss: 0.0146\n",
            "Epoch 387/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0135 - val_loss: 0.0150\n",
            "Epoch 388/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0140 - val_loss: 0.0145\n",
            "Epoch 389/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0138 - val_loss: 0.0145\n",
            "Epoch 390/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0135 - val_loss: 0.0146\n",
            "Epoch 391/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0135 - val_loss: 0.0146\n",
            "Epoch 392/1000\n",
            "1600/1600 [==============================] - 0s 11us/step - loss: 0.0135 - val_loss: 0.0145\n",
            "Epoch 393/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0135 - val_loss: 0.0148\n",
            "Epoch 394/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0137 - val_loss: 0.0148\n",
            "Epoch 395/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0137 - val_loss: 0.0146\n",
            "Epoch 396/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0136 - val_loss: 0.0144\n",
            "Epoch 397/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0137 - val_loss: 0.0147\n",
            "Epoch 398/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0138 - val_loss: 0.0143\n",
            "Epoch 399/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0136 - val_loss: 0.0151\n",
            "Epoch 400/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0137 - val_loss: 0.0146\n",
            "Epoch 401/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0135 - val_loss: 0.0145\n",
            "Epoch 402/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0134 - val_loss: 0.0150\n",
            "Epoch 403/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0136 - val_loss: 0.0144\n",
            "Epoch 404/1000\n",
            "1600/1600 [==============================] - 0s 11us/step - loss: 0.0134 - val_loss: 0.0144\n",
            "Epoch 405/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0134 - val_loss: 0.0145\n",
            "Epoch 406/1000\n",
            "1600/1600 [==============================] - 0s 8us/step - loss: 0.0134 - val_loss: 0.0147\n",
            "Epoch 407/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0135 - val_loss: 0.0147\n",
            "Epoch 408/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0137 - val_loss: 0.0145\n",
            "Epoch 409/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0135 - val_loss: 0.0145\n",
            "Epoch 410/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0134 - val_loss: 0.0152\n",
            "Epoch 411/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0136 - val_loss: 0.0146\n",
            "Epoch 412/1000\n",
            "1600/1600 [==============================] - 0s 11us/step - loss: 0.0135 - val_loss: 0.0147\n",
            "Epoch 413/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0137 - val_loss: 0.0144\n",
            "Epoch 414/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0137 - val_loss: 0.0149\n",
            "Epoch 415/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0137 - val_loss: 0.0150\n",
            "Epoch 416/1000\n",
            "1600/1600 [==============================] - 0s 8us/step - loss: 0.0135 - val_loss: 0.0143\n",
            "Epoch 417/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0136 - val_loss: 0.0147\n",
            "Epoch 418/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0138 - val_loss: 0.0145\n",
            "Epoch 419/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0136 - val_loss: 0.0150\n",
            "Epoch 420/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0135 - val_loss: 0.0146\n",
            "Epoch 421/1000\n",
            "1600/1600 [==============================] - 0s 8us/step - loss: 0.0133 - val_loss: 0.0143\n",
            "Epoch 422/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0133 - val_loss: 0.0144\n",
            "Epoch 423/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0134 - val_loss: 0.0146\n",
            "Epoch 424/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0134 - val_loss: 0.0144\n",
            "Epoch 425/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0133 - val_loss: 0.0144\n",
            "Epoch 426/1000\n",
            "1600/1600 [==============================] - 0s 15us/step - loss: 0.0133 - val_loss: 0.0143\n",
            "Epoch 427/1000\n",
            "1600/1600 [==============================] - 0s 11us/step - loss: 0.0134 - val_loss: 0.0144\n",
            "Epoch 428/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0133 - val_loss: 0.0147\n",
            "Epoch 429/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0134 - val_loss: 0.0148\n",
            "Epoch 430/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0135 - val_loss: 0.0144\n",
            "Epoch 431/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0133 - val_loss: 0.0145\n",
            "Epoch 432/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0136 - val_loss: 0.0145\n",
            "Epoch 433/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0134 - val_loss: 0.0143\n",
            "Epoch 434/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0134 - val_loss: 0.0152\n",
            "Epoch 435/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0135 - val_loss: 0.0144\n",
            "Epoch 436/1000\n",
            "1600/1600 [==============================] - 0s 11us/step - loss: 0.0134 - val_loss: 0.0146\n",
            "Epoch 437/1000\n",
            "1600/1600 [==============================] - 0s 14us/step - loss: 0.0133 - val_loss: 0.0144\n",
            "Epoch 438/1000\n",
            "1600/1600 [==============================] - 0s 14us/step - loss: 0.0133 - val_loss: 0.0147\n",
            "Epoch 439/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0132 - val_loss: 0.0143\n",
            "Epoch 440/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0132 - val_loss: 0.0145\n",
            "Epoch 441/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0133 - val_loss: 0.0147\n",
            "Epoch 442/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0136 - val_loss: 0.0145\n",
            "Epoch 443/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0133 - val_loss: 0.0145\n",
            "Epoch 444/1000\n",
            "1600/1600 [==============================] - 0s 11us/step - loss: 0.0132 - val_loss: 0.0144\n",
            "Epoch 445/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0133 - val_loss: 0.0143\n",
            "Epoch 446/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0133 - val_loss: 0.0150\n",
            "Epoch 447/1000\n",
            "1600/1600 [==============================] - 0s 11us/step - loss: 0.0134 - val_loss: 0.0147\n",
            "Epoch 448/1000\n",
            "1600/1600 [==============================] - 0s 13us/step - loss: 0.0135 - val_loss: 0.0144\n",
            "Epoch 449/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0133 - val_loss: 0.0144\n",
            "Epoch 450/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0131 - val_loss: 0.0144\n",
            "Epoch 451/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0132 - val_loss: 0.0143\n",
            "Epoch 452/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0133 - val_loss: 0.0145\n",
            "Epoch 453/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0137 - val_loss: 0.0155\n",
            "Epoch 454/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0137 - val_loss: 0.0150\n",
            "Epoch 455/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0136 - val_loss: 0.0147\n",
            "Epoch 456/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0135 - val_loss: 0.0145\n",
            "Epoch 457/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0135 - val_loss: 0.0145\n",
            "Epoch 458/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0134 - val_loss: 0.0149\n",
            "Epoch 459/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0135 - val_loss: 0.0142\n",
            "Epoch 460/1000\n",
            "1600/1600 [==============================] - 0s 8us/step - loss: 0.0135 - val_loss: 0.0146\n",
            "Epoch 461/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0134 - val_loss: 0.0143\n",
            "Epoch 462/1000\n",
            "1600/1600 [==============================] - 0s 12us/step - loss: 0.0134 - val_loss: 0.0145\n",
            "Epoch 463/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0133 - val_loss: 0.0145\n",
            "Epoch 464/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0132 - val_loss: 0.0147\n",
            "Epoch 465/1000\n",
            "1600/1600 [==============================] - 0s 8us/step - loss: 0.0133 - val_loss: 0.0142\n",
            "Epoch 466/1000\n",
            "1600/1600 [==============================] - 0s 11us/step - loss: 0.0133 - val_loss: 0.0147\n",
            "Epoch 467/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0133 - val_loss: 0.0143\n",
            "Epoch 468/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0134 - val_loss: 0.0148\n",
            "Epoch 469/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0136 - val_loss: 0.0143\n",
            "Epoch 470/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0134 - val_loss: 0.0146\n",
            "Epoch 471/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0136 - val_loss: 0.0144\n",
            "Epoch 472/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0133 - val_loss: 0.0146\n",
            "Epoch 473/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0132 - val_loss: 0.0143\n",
            "Epoch 474/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0132 - val_loss: 0.0146\n",
            "Epoch 475/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0133 - val_loss: 0.0144\n",
            "Epoch 476/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0135 - val_loss: 0.0144\n",
            "Epoch 477/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0134 - val_loss: 0.0145\n",
            "Epoch 478/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0134 - val_loss: 0.0145\n",
            "Epoch 479/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0134 - val_loss: 0.0142\n",
            "Epoch 480/1000\n",
            "1600/1600 [==============================] - 0s 11us/step - loss: 0.0135 - val_loss: 0.0148\n",
            "Epoch 481/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0134 - val_loss: 0.0148\n",
            "Epoch 482/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0136 - val_loss: 0.0143\n",
            "Epoch 483/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0131 - val_loss: 0.0146\n",
            "Epoch 484/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0135 - val_loss: 0.0143\n",
            "Epoch 485/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0136 - val_loss: 0.0150\n",
            "Epoch 486/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0135 - val_loss: 0.0142\n",
            "Epoch 487/1000\n",
            "1600/1600 [==============================] - 0s 11us/step - loss: 0.0136 - val_loss: 0.0145\n",
            "Epoch 488/1000\n",
            "1600/1600 [==============================] - 0s 11us/step - loss: 0.0133 - val_loss: 0.0144\n",
            "Epoch 489/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0131 - val_loss: 0.0145\n",
            "Epoch 490/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0131 - val_loss: 0.0144\n",
            "Epoch 491/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0131 - val_loss: 0.0144\n",
            "Epoch 492/1000\n",
            "1600/1600 [==============================] - 0s 8us/step - loss: 0.0131 - val_loss: 0.0146\n",
            "Epoch 493/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0132 - val_loss: 0.0144\n",
            "Epoch 494/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0133 - val_loss: 0.0144\n",
            "Epoch 495/1000\n",
            "1600/1600 [==============================] - 0s 8us/step - loss: 0.0134 - val_loss: 0.0145\n",
            "Epoch 496/1000\n",
            "1600/1600 [==============================] - 0s 11us/step - loss: 0.0131 - val_loss: 0.0150\n",
            "Epoch 497/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0134 - val_loss: 0.0145\n",
            "Epoch 498/1000\n",
            "1600/1600 [==============================] - 0s 12us/step - loss: 0.0133 - val_loss: 0.0146\n",
            "Epoch 499/1000\n",
            "1600/1600 [==============================] - 0s 8us/step - loss: 0.0134 - val_loss: 0.0144\n",
            "Epoch 500/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0131 - val_loss: 0.0147\n",
            "Epoch 501/1000\n",
            "1600/1600 [==============================] - 0s 11us/step - loss: 0.0134 - val_loss: 0.0145\n",
            "Epoch 502/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0133 - val_loss: 0.0144\n",
            "Epoch 503/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0133 - val_loss: 0.0146\n",
            "Epoch 504/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0131 - val_loss: 0.0144\n",
            "Epoch 505/1000\n",
            "1600/1600 [==============================] - 0s 18us/step - loss: 0.0131 - val_loss: 0.0144\n",
            "Epoch 506/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0132 - val_loss: 0.0147\n",
            "Epoch 507/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0132 - val_loss: 0.0144\n",
            "Epoch 508/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0134 - val_loss: 0.0144\n",
            "Epoch 509/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0133 - val_loss: 0.0148\n",
            "Epoch 510/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0133 - val_loss: 0.0145\n",
            "Epoch 511/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0133 - val_loss: 0.0148\n",
            "Epoch 512/1000\n",
            "1600/1600 [==============================] - 0s 8us/step - loss: 0.0134 - val_loss: 0.0143\n",
            "Epoch 513/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0131 - val_loss: 0.0146\n",
            "Epoch 514/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0132 - val_loss: 0.0143\n",
            "Epoch 515/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0133 - val_loss: 0.0144\n",
            "Epoch 516/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0131 - val_loss: 0.0148\n",
            "Epoch 517/1000\n",
            "1600/1600 [==============================] - 0s 8us/step - loss: 0.0131 - val_loss: 0.0143\n",
            "Epoch 518/1000\n",
            "1600/1600 [==============================] - 0s 8us/step - loss: 0.0132 - val_loss: 0.0145\n",
            "Epoch 519/1000\n",
            "1600/1600 [==============================] - 0s 11us/step - loss: 0.0132 - val_loss: 0.0144\n",
            "Epoch 520/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0131 - val_loss: 0.0147\n",
            "Epoch 521/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0132 - val_loss: 0.0145\n",
            "Epoch 522/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0132 - val_loss: 0.0143\n",
            "Epoch 523/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0131 - val_loss: 0.0145\n",
            "Epoch 524/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0131 - val_loss: 0.0145\n",
            "Epoch 525/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0133 - val_loss: 0.0144\n",
            "Epoch 526/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0131 - val_loss: 0.0143\n",
            "Epoch 527/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0132 - val_loss: 0.0144\n",
            "Epoch 528/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0131 - val_loss: 0.0143\n",
            "Epoch 529/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0131 - val_loss: 0.0144\n",
            "Epoch 530/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0131 - val_loss: 0.0143\n",
            "Epoch 531/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0131 - val_loss: 0.0149\n",
            "Epoch 532/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0132 - val_loss: 0.0143\n",
            "Epoch 533/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0133 - val_loss: 0.0150\n",
            "Epoch 534/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0133 - val_loss: 0.0146\n",
            "Epoch 535/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0139 - val_loss: 0.0148\n",
            "Epoch 536/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0131 - val_loss: 0.0143\n",
            "Epoch 537/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0131 - val_loss: 0.0146\n",
            "Epoch 538/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0131 - val_loss: 0.0144\n",
            "Epoch 539/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0131 - val_loss: 0.0147\n",
            "Epoch 540/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0131 - val_loss: 0.0144\n",
            "Epoch 541/1000\n",
            "1600/1600 [==============================] - 0s 11us/step - loss: 0.0131 - val_loss: 0.0145\n",
            "Epoch 542/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0132 - val_loss: 0.0145\n",
            "Epoch 543/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0132 - val_loss: 0.0147\n",
            "Epoch 544/1000\n",
            "1600/1600 [==============================] - 0s 11us/step - loss: 0.0130 - val_loss: 0.0141\n",
            "Epoch 545/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0131 - val_loss: 0.0151\n",
            "Epoch 546/1000\n",
            "1600/1600 [==============================] - 0s 11us/step - loss: 0.0133 - val_loss: 0.0145\n",
            "Epoch 547/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0132 - val_loss: 0.0146\n",
            "Epoch 548/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0132 - val_loss: 0.0144\n",
            "Epoch 549/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0133 - val_loss: 0.0145\n",
            "Epoch 550/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0132 - val_loss: 0.0147\n",
            "Epoch 551/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0135 - val_loss: 0.0143\n",
            "Epoch 552/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0132 - val_loss: 0.0148\n",
            "Epoch 553/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0132 - val_loss: 0.0145\n",
            "Epoch 554/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0131 - val_loss: 0.0143\n",
            "Epoch 555/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0131 - val_loss: 0.0144\n",
            "Epoch 556/1000\n",
            "1600/1600 [==============================] - 0s 11us/step - loss: 0.0132 - val_loss: 0.0145\n",
            "Epoch 557/1000\n",
            "1600/1600 [==============================] - 0s 15us/step - loss: 0.0131 - val_loss: 0.0144\n",
            "Epoch 558/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0131 - val_loss: 0.0143\n",
            "Epoch 559/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0131 - val_loss: 0.0145\n",
            "Epoch 560/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0131 - val_loss: 0.0146\n",
            "Epoch 561/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0132 - val_loss: 0.0144\n",
            "Epoch 562/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0133 - val_loss: 0.0145\n",
            "Epoch 563/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0134 - val_loss: 0.0143\n",
            "Epoch 564/1000\n",
            "1600/1600 [==============================] - 0s 8us/step - loss: 0.0133 - val_loss: 0.0148\n",
            "Epoch 565/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0133 - val_loss: 0.0144\n",
            "Epoch 566/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0132 - val_loss: 0.0147\n",
            "Epoch 567/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0132 - val_loss: 0.0143\n",
            "Epoch 568/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0131 - val_loss: 0.0144\n",
            "Epoch 569/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0131 - val_loss: 0.0145\n",
            "Epoch 570/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0132 - val_loss: 0.0145\n",
            "Epoch 571/1000\n",
            "1600/1600 [==============================] - 0s 11us/step - loss: 0.0131 - val_loss: 0.0144\n",
            "Epoch 572/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0132 - val_loss: 0.0146\n",
            "Epoch 573/1000\n",
            "1600/1600 [==============================] - 0s 8us/step - loss: 0.0134 - val_loss: 0.0148\n",
            "Epoch 574/1000\n",
            "1600/1600 [==============================] - 0s 11us/step - loss: 0.0134 - val_loss: 0.0143\n",
            "Epoch 575/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0133 - val_loss: 0.0147\n",
            "Epoch 576/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0132 - val_loss: 0.0144\n",
            "Epoch 577/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0134 - val_loss: 0.0143\n",
            "Epoch 578/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0131 - val_loss: 0.0145\n",
            "Epoch 579/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0132 - val_loss: 0.0143\n",
            "Epoch 580/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0132 - val_loss: 0.0148\n",
            "Epoch 581/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0134 - val_loss: 0.0146\n",
            "Epoch 582/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0131 - val_loss: 0.0148\n",
            "Epoch 583/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0132 - val_loss: 0.0143\n",
            "Epoch 584/1000\n",
            "1600/1600 [==============================] - 0s 12us/step - loss: 0.0131 - val_loss: 0.0144\n",
            "Epoch 585/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0131 - val_loss: 0.0146\n",
            "Epoch 586/1000\n",
            "1600/1600 [==============================] - 0s 8us/step - loss: 0.0131 - val_loss: 0.0148\n",
            "Epoch 587/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0132 - val_loss: 0.0145\n",
            "Epoch 588/1000\n",
            "1600/1600 [==============================] - 0s 8us/step - loss: 0.0131 - val_loss: 0.0143\n",
            "Epoch 589/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0131 - val_loss: 0.0146\n",
            "Epoch 590/1000\n",
            "1600/1600 [==============================] - 0s 8us/step - loss: 0.0134 - val_loss: 0.0145\n",
            "Epoch 591/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0133 - val_loss: 0.0144\n",
            "Epoch 592/1000\n",
            "1600/1600 [==============================] - 0s 8us/step - loss: 0.0131 - val_loss: 0.0146\n",
            "Epoch 593/1000\n",
            "1600/1600 [==============================] - 0s 8us/step - loss: 0.0131 - val_loss: 0.0141\n",
            "Epoch 594/1000\n",
            "1600/1600 [==============================] - 0s 11us/step - loss: 0.0135 - val_loss: 0.0147\n",
            "Epoch 595/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0137 - val_loss: 0.0147\n",
            "Epoch 596/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0132 - val_loss: 0.0150\n",
            "Epoch 597/1000\n",
            "1600/1600 [==============================] - 0s 8us/step - loss: 0.0137 - val_loss: 0.0146\n",
            "Epoch 598/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0132 - val_loss: 0.0143\n",
            "Epoch 599/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0132 - val_loss: 0.0147\n",
            "Epoch 600/1000\n",
            "1600/1600 [==============================] - 0s 8us/step - loss: 0.0131 - val_loss: 0.0145\n",
            "Epoch 601/1000\n",
            "1600/1600 [==============================] - 0s 11us/step - loss: 0.0133 - val_loss: 0.0145\n",
            "Epoch 602/1000\n",
            "1600/1600 [==============================] - 0s 12us/step - loss: 0.0131 - val_loss: 0.0147\n",
            "Epoch 603/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0134 - val_loss: 0.0143\n",
            "Epoch 604/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0131 - val_loss: 0.0146\n",
            "Epoch 605/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0131 - val_loss: 0.0145\n",
            "Epoch 606/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0131 - val_loss: 0.0147\n",
            "Epoch 607/1000\n",
            "1600/1600 [==============================] - 0s 12us/step - loss: 0.0132 - val_loss: 0.0144\n",
            "Epoch 608/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0131 - val_loss: 0.0147\n",
            "Epoch 609/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0131 - val_loss: 0.0144\n",
            "Epoch 610/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0131 - val_loss: 0.0143\n",
            "Epoch 611/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0131 - val_loss: 0.0145\n",
            "Epoch 612/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0131 - val_loss: 0.0145\n",
            "Epoch 613/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0130 - val_loss: 0.0148\n",
            "Epoch 614/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0134 - val_loss: 0.0146\n",
            "Epoch 615/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0131 - val_loss: 0.0143\n",
            "Epoch 616/1000\n",
            "1600/1600 [==============================] - 0s 8us/step - loss: 0.0130 - val_loss: 0.0146\n",
            "Epoch 617/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0130 - val_loss: 0.0144\n",
            "Epoch 618/1000\n",
            "1600/1600 [==============================] - 0s 8us/step - loss: 0.0130 - val_loss: 0.0143\n",
            "Epoch 619/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0132 - val_loss: 0.0143\n",
            "Epoch 620/1000\n",
            "1600/1600 [==============================] - 0s 12us/step - loss: 0.0131 - val_loss: 0.0147\n",
            "Epoch 621/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0133 - val_loss: 0.0144\n",
            "Epoch 622/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0131 - val_loss: 0.0150\n",
            "Epoch 623/1000\n",
            "1600/1600 [==============================] - 0s 11us/step - loss: 0.0132 - val_loss: 0.0144\n",
            "Epoch 624/1000\n",
            "1600/1600 [==============================] - 0s 11us/step - loss: 0.0132 - val_loss: 0.0146\n",
            "Epoch 625/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0134 - val_loss: 0.0142\n",
            "Epoch 626/1000\n",
            "1600/1600 [==============================] - 0s 12us/step - loss: 0.0132 - val_loss: 0.0145\n",
            "Epoch 627/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0131 - val_loss: 0.0146\n",
            "Epoch 628/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0131 - val_loss: 0.0145\n",
            "Epoch 629/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0131 - val_loss: 0.0144\n",
            "Epoch 630/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0132 - val_loss: 0.0147\n",
            "Epoch 631/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0131 - val_loss: 0.0147\n",
            "Epoch 632/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0132 - val_loss: 0.0145\n",
            "Epoch 633/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0134 - val_loss: 0.0150\n",
            "Epoch 634/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0135 - val_loss: 0.0144\n",
            "Epoch 635/1000\n",
            "1600/1600 [==============================] - 0s 8us/step - loss: 0.0132 - val_loss: 0.0143\n",
            "Epoch 636/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0131 - val_loss: 0.0148\n",
            "Epoch 637/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0131 - val_loss: 0.0143\n",
            "Epoch 638/1000\n",
            "1600/1600 [==============================] - 0s 11us/step - loss: 0.0130 - val_loss: 0.0146\n",
            "Epoch 639/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0131 - val_loss: 0.0146\n",
            "Epoch 640/1000\n",
            "1600/1600 [==============================] - 0s 12us/step - loss: 0.0132 - val_loss: 0.0146\n",
            "Epoch 641/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0136 - val_loss: 0.0144\n",
            "Epoch 642/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0136 - val_loss: 0.0147\n",
            "Epoch 643/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0134 - val_loss: 0.0151\n",
            "Epoch 644/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0132 - val_loss: 0.0146\n",
            "Epoch 645/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0135 - val_loss: 0.0147\n",
            "Epoch 646/1000\n",
            "1600/1600 [==============================] - 0s 11us/step - loss: 0.0133 - val_loss: 0.0143\n",
            "Epoch 647/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0131 - val_loss: 0.0144\n",
            "Epoch 648/1000\n",
            "1600/1600 [==============================] - 0s 8us/step - loss: 0.0130 - val_loss: 0.0144\n",
            "Epoch 649/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0130 - val_loss: 0.0146\n",
            "Epoch 650/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0130 - val_loss: 0.0147\n",
            "Epoch 651/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0131 - val_loss: 0.0148\n",
            "Epoch 652/1000\n",
            "1600/1600 [==============================] - 0s 11us/step - loss: 0.0133 - val_loss: 0.0142\n",
            "Epoch 653/1000\n",
            "1600/1600 [==============================] - 0s 8us/step - loss: 0.0131 - val_loss: 0.0147\n",
            "Epoch 654/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0130 - val_loss: 0.0147\n",
            "Epoch 655/1000\n",
            "1600/1600 [==============================] - 0s 11us/step - loss: 0.0132 - val_loss: 0.0150\n",
            "Epoch 656/1000\n",
            "1600/1600 [==============================] - 0s 8us/step - loss: 0.0132 - val_loss: 0.0144\n",
            "Epoch 657/1000\n",
            "1600/1600 [==============================] - 0s 8us/step - loss: 0.0132 - val_loss: 0.0149\n",
            "Epoch 658/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0133 - val_loss: 0.0144\n",
            "Epoch 659/1000\n",
            "1600/1600 [==============================] - 0s 8us/step - loss: 0.0134 - val_loss: 0.0151\n",
            "Epoch 660/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0132 - val_loss: 0.0147\n",
            "Epoch 661/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0131 - val_loss: 0.0143\n",
            "Epoch 662/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0131 - val_loss: 0.0142\n",
            "Epoch 663/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0134 - val_loss: 0.0152\n",
            "Epoch 664/1000\n",
            "1600/1600 [==============================] - 0s 12us/step - loss: 0.0133 - val_loss: 0.0144\n",
            "Epoch 665/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0132 - val_loss: 0.0144\n",
            "Epoch 666/1000\n",
            "1600/1600 [==============================] - 0s 7us/step - loss: 0.0131 - val_loss: 0.0144\n",
            "Epoch 667/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0131 - val_loss: 0.0148\n",
            "Epoch 668/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0131 - val_loss: 0.0143\n",
            "Epoch 669/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0132 - val_loss: 0.0146\n",
            "Epoch 670/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0135 - val_loss: 0.0143\n",
            "Epoch 671/1000\n",
            "1600/1600 [==============================] - 0s 12us/step - loss: 0.0133 - val_loss: 0.0154\n",
            "Epoch 672/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0134 - val_loss: 0.0145\n",
            "Epoch 673/1000\n",
            "1600/1600 [==============================] - 0s 8us/step - loss: 0.0133 - val_loss: 0.0146\n",
            "Epoch 674/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0131 - val_loss: 0.0143\n",
            "Epoch 675/1000\n",
            "1600/1600 [==============================] - 0s 7us/step - loss: 0.0132 - val_loss: 0.0145\n",
            "Epoch 676/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0130 - val_loss: 0.0146\n",
            "Epoch 677/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0132 - val_loss: 0.0144\n",
            "Epoch 678/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0133 - val_loss: 0.0152\n",
            "Epoch 679/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0136 - val_loss: 0.0143\n",
            "Epoch 680/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0138 - val_loss: 0.0148\n",
            "Epoch 681/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0132 - val_loss: 0.0150\n",
            "Epoch 682/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0131 - val_loss: 0.0144\n",
            "Epoch 683/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0130 - val_loss: 0.0146\n",
            "Epoch 684/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0130 - val_loss: 0.0143\n",
            "Epoch 685/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0132 - val_loss: 0.0149\n",
            "Epoch 686/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0133 - val_loss: 0.0142\n",
            "Epoch 687/1000\n",
            "1600/1600 [==============================] - 0s 11us/step - loss: 0.0132 - val_loss: 0.0143\n",
            "Epoch 688/1000\n",
            "1600/1600 [==============================] - 0s 15us/step - loss: 0.0130 - val_loss: 0.0144\n",
            "Epoch 689/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0133 - val_loss: 0.0148\n",
            "Epoch 690/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0131 - val_loss: 0.0145\n",
            "Epoch 691/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0131 - val_loss: 0.0142\n",
            "Epoch 692/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0131 - val_loss: 0.0146\n",
            "Epoch 693/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0130 - val_loss: 0.0146\n",
            "Epoch 694/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0130 - val_loss: 0.0145\n",
            "Epoch 695/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0130 - val_loss: 0.0144\n",
            "Epoch 696/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0130 - val_loss: 0.0145\n",
            "Epoch 697/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0130 - val_loss: 0.0148\n",
            "Epoch 698/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0131 - val_loss: 0.0144\n",
            "Epoch 699/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0130 - val_loss: 0.0144\n",
            "Epoch 700/1000\n",
            "1600/1600 [==============================] - 0s 8us/step - loss: 0.0131 - val_loss: 0.0145\n",
            "Epoch 701/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0134 - val_loss: 0.0148\n",
            "Epoch 702/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0131 - val_loss: 0.0146\n",
            "Epoch 703/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0131 - val_loss: 0.0147\n",
            "Epoch 704/1000\n",
            "1600/1600 [==============================] - 0s 8us/step - loss: 0.0132 - val_loss: 0.0144\n",
            "Epoch 705/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0130 - val_loss: 0.0145\n",
            "Epoch 706/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0132 - val_loss: 0.0143\n",
            "Epoch 707/1000\n",
            "1600/1600 [==============================] - 0s 8us/step - loss: 0.0132 - val_loss: 0.0147\n",
            "Epoch 708/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0132 - val_loss: 0.0147\n",
            "Epoch 709/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0134 - val_loss: 0.0145\n",
            "Epoch 710/1000\n",
            "1600/1600 [==============================] - 0s 12us/step - loss: 0.0131 - val_loss: 0.0146\n",
            "Epoch 711/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0132 - val_loss: 0.0146\n",
            "Epoch 712/1000\n",
            "1600/1600 [==============================] - 0s 11us/step - loss: 0.0134 - val_loss: 0.0145\n",
            "Epoch 713/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0131 - val_loss: 0.0146\n",
            "Epoch 714/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0131 - val_loss: 0.0142\n",
            "Epoch 715/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0130 - val_loss: 0.0145\n",
            "Epoch 716/1000\n",
            "1600/1600 [==============================] - 0s 8us/step - loss: 0.0131 - val_loss: 0.0145\n",
            "Epoch 717/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0132 - val_loss: 0.0145\n",
            "Epoch 718/1000\n",
            "1600/1600 [==============================] - 0s 11us/step - loss: 0.0130 - val_loss: 0.0142\n",
            "Epoch 719/1000\n",
            "1600/1600 [==============================] - 0s 8us/step - loss: 0.0130 - val_loss: 0.0146\n",
            "Epoch 720/1000\n",
            "1600/1600 [==============================] - 0s 13us/step - loss: 0.0130 - val_loss: 0.0144\n",
            "Epoch 721/1000\n",
            "1600/1600 [==============================] - 0s 8us/step - loss: 0.0130 - val_loss: 0.0145\n",
            "Epoch 722/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0130 - val_loss: 0.0148\n",
            "Epoch 723/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0132 - val_loss: 0.0143\n",
            "Epoch 724/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0131 - val_loss: 0.0143\n",
            "Epoch 725/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0131 - val_loss: 0.0144\n",
            "Epoch 726/1000\n",
            "1600/1600 [==============================] - 0s 8us/step - loss: 0.0130 - val_loss: 0.0146\n",
            "Epoch 727/1000\n",
            "1600/1600 [==============================] - 0s 8us/step - loss: 0.0131 - val_loss: 0.0144\n",
            "Epoch 728/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0132 - val_loss: 0.0142\n",
            "Epoch 729/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0133 - val_loss: 0.0147\n",
            "Epoch 730/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0131 - val_loss: 0.0144\n",
            "Epoch 731/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0131 - val_loss: 0.0151\n",
            "Epoch 732/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0133 - val_loss: 0.0147\n",
            "Epoch 733/1000\n",
            "1600/1600 [==============================] - 0s 12us/step - loss: 0.0131 - val_loss: 0.0142\n",
            "Epoch 734/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0131 - val_loss: 0.0147\n",
            "Epoch 735/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0131 - val_loss: 0.0143\n",
            "Epoch 736/1000\n",
            "1600/1600 [==============================] - 0s 8us/step - loss: 0.0130 - val_loss: 0.0143\n",
            "Epoch 737/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0131 - val_loss: 0.0145\n",
            "Epoch 738/1000\n",
            "1600/1600 [==============================] - 0s 8us/step - loss: 0.0129 - val_loss: 0.0142\n",
            "Epoch 739/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0130 - val_loss: 0.0145\n",
            "Epoch 740/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0131 - val_loss: 0.0146\n",
            "Epoch 741/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0130 - val_loss: 0.0143\n",
            "Epoch 742/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0131 - val_loss: 0.0145\n",
            "Epoch 743/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0130 - val_loss: 0.0145\n",
            "Epoch 744/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0131 - val_loss: 0.0144\n",
            "Epoch 745/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0132 - val_loss: 0.0144\n",
            "Epoch 746/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0132 - val_loss: 0.0148\n",
            "Epoch 747/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0131 - val_loss: 0.0144\n",
            "Epoch 748/1000\n",
            "1600/1600 [==============================] - 0s 11us/step - loss: 0.0133 - val_loss: 0.0148\n",
            "Epoch 749/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0131 - val_loss: 0.0143\n",
            "Epoch 750/1000\n",
            "1600/1600 [==============================] - 0s 8us/step - loss: 0.0132 - val_loss: 0.0147\n",
            "Epoch 751/1000\n",
            "1600/1600 [==============================] - 0s 8us/step - loss: 0.0131 - val_loss: 0.0145\n",
            "Epoch 752/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0133 - val_loss: 0.0145\n",
            "Epoch 753/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0131 - val_loss: 0.0144\n",
            "Epoch 754/1000\n",
            "1600/1600 [==============================] - 0s 13us/step - loss: 0.0132 - val_loss: 0.0148\n",
            "Epoch 755/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0134 - val_loss: 0.0157\n",
            "Epoch 756/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0135 - val_loss: 0.0152\n",
            "Epoch 757/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0135 - val_loss: 0.0142\n",
            "Epoch 758/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0133 - val_loss: 0.0146\n",
            "Epoch 759/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0133 - val_loss: 0.0144\n",
            "Epoch 760/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0131 - val_loss: 0.0144\n",
            "Epoch 761/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0130 - val_loss: 0.0144\n",
            "Epoch 762/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0131 - val_loss: 0.0145\n",
            "Epoch 763/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0131 - val_loss: 0.0149\n",
            "Epoch 764/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0135 - val_loss: 0.0146\n",
            "Epoch 765/1000\n",
            "1600/1600 [==============================] - 0s 8us/step - loss: 0.0130 - val_loss: 0.0144\n",
            "Epoch 766/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0131 - val_loss: 0.0143\n",
            "Epoch 767/1000\n",
            "1600/1600 [==============================] - 0s 8us/step - loss: 0.0130 - val_loss: 0.0149\n",
            "Epoch 768/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0130 - val_loss: 0.0142\n",
            "Epoch 769/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0130 - val_loss: 0.0145\n",
            "Epoch 770/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0131 - val_loss: 0.0144\n",
            "Epoch 771/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0130 - val_loss: 0.0144\n",
            "Epoch 772/1000\n",
            "1600/1600 [==============================] - 0s 11us/step - loss: 0.0130 - val_loss: 0.0145\n",
            "Epoch 773/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0130 - val_loss: 0.0144\n",
            "Epoch 774/1000\n",
            "1600/1600 [==============================] - 0s 8us/step - loss: 0.0130 - val_loss: 0.0145\n",
            "Epoch 775/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0130 - val_loss: 0.0144\n",
            "Epoch 776/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0130 - val_loss: 0.0143\n",
            "Epoch 777/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0131 - val_loss: 0.0148\n",
            "Epoch 778/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0130 - val_loss: 0.0143\n",
            "Epoch 779/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0131 - val_loss: 0.0145\n",
            "Epoch 780/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0132 - val_loss: 0.0148\n",
            "Epoch 781/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0132 - val_loss: 0.0151\n",
            "Epoch 782/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0137 - val_loss: 0.0142\n",
            "Epoch 783/1000\n",
            "1600/1600 [==============================] - 0s 8us/step - loss: 0.0133 - val_loss: 0.0148\n",
            "Epoch 784/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0135 - val_loss: 0.0143\n",
            "Epoch 785/1000\n",
            "1600/1600 [==============================] - 0s 11us/step - loss: 0.0131 - val_loss: 0.0149\n",
            "Epoch 786/1000\n",
            "1600/1600 [==============================] - 0s 15us/step - loss: 0.0131 - val_loss: 0.0148\n",
            "Epoch 787/1000\n",
            "1600/1600 [==============================] - 0s 13us/step - loss: 0.0132 - val_loss: 0.0146\n",
            "Epoch 788/1000\n",
            "1600/1600 [==============================] - 0s 11us/step - loss: 0.0131 - val_loss: 0.0144\n",
            "Epoch 789/1000\n",
            "1600/1600 [==============================] - 0s 11us/step - loss: 0.0131 - val_loss: 0.0143\n",
            "Epoch 790/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0130 - val_loss: 0.0146\n",
            "Epoch 791/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0130 - val_loss: 0.0142\n",
            "Epoch 792/1000\n",
            "1600/1600 [==============================] - 0s 8us/step - loss: 0.0130 - val_loss: 0.0144\n",
            "Epoch 793/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0130 - val_loss: 0.0145\n",
            "Epoch 794/1000\n",
            "1600/1600 [==============================] - 0s 14us/step - loss: 0.0131 - val_loss: 0.0145\n",
            "Epoch 795/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0130 - val_loss: 0.0144\n",
            "Epoch 796/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0130 - val_loss: 0.0144\n",
            "Epoch 797/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0130 - val_loss: 0.0143\n",
            "Epoch 798/1000\n",
            "1600/1600 [==============================] - 0s 11us/step - loss: 0.0131 - val_loss: 0.0146\n",
            "Epoch 799/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0131 - val_loss: 0.0152\n",
            "Epoch 800/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0133 - val_loss: 0.0144\n",
            "Epoch 801/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0134 - val_loss: 0.0144\n",
            "Epoch 802/1000\n",
            "1600/1600 [==============================] - 0s 12us/step - loss: 0.0132 - val_loss: 0.0146\n",
            "Epoch 803/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0132 - val_loss: 0.0143\n",
            "Epoch 804/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0132 - val_loss: 0.0146\n",
            "Epoch 805/1000\n",
            "1600/1600 [==============================] - 0s 8us/step - loss: 0.0130 - val_loss: 0.0143\n",
            "Epoch 806/1000\n",
            "1600/1600 [==============================] - 0s 8us/step - loss: 0.0129 - val_loss: 0.0147\n",
            "Epoch 807/1000\n",
            "1600/1600 [==============================] - 0s 8us/step - loss: 0.0135 - val_loss: 0.0145\n",
            "Epoch 808/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0130 - val_loss: 0.0146\n",
            "Epoch 809/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0130 - val_loss: 0.0146\n",
            "Epoch 810/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0131 - val_loss: 0.0142\n",
            "Epoch 811/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0130 - val_loss: 0.0145\n",
            "Epoch 812/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0129 - val_loss: 0.0143\n",
            "Epoch 813/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0131 - val_loss: 0.0144\n",
            "Epoch 814/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0130 - val_loss: 0.0143\n",
            "Epoch 815/1000\n",
            "1600/1600 [==============================] - 0s 8us/step - loss: 0.0130 - val_loss: 0.0144\n",
            "Epoch 816/1000\n",
            "1600/1600 [==============================] - 0s 8us/step - loss: 0.0131 - val_loss: 0.0145\n",
            "Epoch 817/1000\n",
            "1600/1600 [==============================] - 0s 8us/step - loss: 0.0131 - val_loss: 0.0143\n",
            "Epoch 818/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0135 - val_loss: 0.0153\n",
            "Epoch 819/1000\n",
            "1600/1600 [==============================] - 0s 8us/step - loss: 0.0133 - val_loss: 0.0147\n",
            "Epoch 820/1000\n",
            "1600/1600 [==============================] - 0s 8us/step - loss: 0.0132 - val_loss: 0.0147\n",
            "Epoch 821/1000\n",
            "1600/1600 [==============================] - 0s 8us/step - loss: 0.0132 - val_loss: 0.0143\n",
            "Epoch 822/1000\n",
            "1600/1600 [==============================] - 0s 8us/step - loss: 0.0130 - val_loss: 0.0144\n",
            "Epoch 823/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0130 - val_loss: 0.0142\n",
            "Epoch 824/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0130 - val_loss: 0.0148\n",
            "Epoch 825/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0136 - val_loss: 0.0143\n",
            "Epoch 826/1000\n",
            "1600/1600 [==============================] - 0s 8us/step - loss: 0.0134 - val_loss: 0.0148\n",
            "Epoch 827/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0132 - val_loss: 0.0150\n",
            "Epoch 828/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0135 - val_loss: 0.0146\n",
            "Epoch 829/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0132 - val_loss: 0.0149\n",
            "Epoch 830/1000\n",
            "1600/1600 [==============================] - 0s 8us/step - loss: 0.0132 - val_loss: 0.0147\n",
            "Epoch 831/1000\n",
            "1600/1600 [==============================] - 0s 8us/step - loss: 0.0139 - val_loss: 0.0151\n",
            "Epoch 832/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0134 - val_loss: 0.0146\n",
            "Epoch 833/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0133 - val_loss: 0.0149\n",
            "Epoch 834/1000\n",
            "1600/1600 [==============================] - 0s 11us/step - loss: 0.0134 - val_loss: 0.0143\n",
            "Epoch 835/1000\n",
            "1600/1600 [==============================] - 0s 8us/step - loss: 0.0131 - val_loss: 0.0149\n",
            "Epoch 836/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0131 - val_loss: 0.0144\n",
            "Epoch 837/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0130 - val_loss: 0.0143\n",
            "Epoch 838/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0130 - val_loss: 0.0143\n",
            "Epoch 839/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0130 - val_loss: 0.0146\n",
            "Epoch 840/1000\n",
            "1600/1600 [==============================] - 0s 11us/step - loss: 0.0130 - val_loss: 0.0144\n",
            "Epoch 841/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0131 - val_loss: 0.0144\n",
            "Epoch 842/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0129 - val_loss: 0.0145\n",
            "Epoch 843/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0130 - val_loss: 0.0143\n",
            "Epoch 844/1000\n",
            "1600/1600 [==============================] - 0s 8us/step - loss: 0.0131 - val_loss: 0.0143\n",
            "Epoch 845/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0130 - val_loss: 0.0144\n",
            "Epoch 846/1000\n",
            "1600/1600 [==============================] - 0s 8us/step - loss: 0.0130 - val_loss: 0.0143\n",
            "Epoch 847/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0130 - val_loss: 0.0144\n",
            "Epoch 848/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0131 - val_loss: 0.0146\n",
            "Epoch 849/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0131 - val_loss: 0.0144\n",
            "Epoch 850/1000\n",
            "1600/1600 [==============================] - 0s 8us/step - loss: 0.0130 - val_loss: 0.0141\n",
            "Epoch 851/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0131 - val_loss: 0.0146\n",
            "Epoch 852/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0130 - val_loss: 0.0144\n",
            "Epoch 853/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0130 - val_loss: 0.0144\n",
            "Epoch 854/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0131 - val_loss: 0.0147\n",
            "Epoch 855/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0130 - val_loss: 0.0146\n",
            "Epoch 856/1000\n",
            "1600/1600 [==============================] - 0s 11us/step - loss: 0.0133 - val_loss: 0.0144\n",
            "Epoch 857/1000\n",
            "1600/1600 [==============================] - 0s 8us/step - loss: 0.0132 - val_loss: 0.0144\n",
            "Epoch 858/1000\n",
            "1600/1600 [==============================] - 0s 8us/step - loss: 0.0131 - val_loss: 0.0144\n",
            "Epoch 859/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0130 - val_loss: 0.0146\n",
            "Epoch 860/1000\n",
            "1600/1600 [==============================] - 0s 11us/step - loss: 0.0131 - val_loss: 0.0145\n",
            "Epoch 861/1000\n",
            "1600/1600 [==============================] - 0s 11us/step - loss: 0.0129 - val_loss: 0.0142\n",
            "Epoch 862/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0130 - val_loss: 0.0143\n",
            "Epoch 863/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0129 - val_loss: 0.0146\n",
            "Epoch 864/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0131 - val_loss: 0.0147\n",
            "Epoch 865/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0132 - val_loss: 0.0145\n",
            "Epoch 866/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0134 - val_loss: 0.0149\n",
            "Epoch 867/1000\n",
            "1600/1600 [==============================] - 0s 8us/step - loss: 0.0133 - val_loss: 0.0145\n",
            "Epoch 868/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0134 - val_loss: 0.0149\n",
            "Epoch 869/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0133 - val_loss: 0.0146\n",
            "Epoch 870/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0132 - val_loss: 0.0147\n",
            "Epoch 871/1000\n",
            "1600/1600 [==============================] - 0s 8us/step - loss: 0.0132 - val_loss: 0.0146\n",
            "Epoch 872/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0131 - val_loss: 0.0152\n",
            "Epoch 873/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0135 - val_loss: 0.0147\n",
            "Epoch 874/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0138 - val_loss: 0.0145\n",
            "Epoch 875/1000\n",
            "1600/1600 [==============================] - 0s 8us/step - loss: 0.0132 - val_loss: 0.0147\n",
            "Epoch 876/1000\n",
            "1600/1600 [==============================] - 0s 8us/step - loss: 0.0133 - val_loss: 0.0142\n",
            "Epoch 877/1000\n",
            "1600/1600 [==============================] - 0s 8us/step - loss: 0.0134 - val_loss: 0.0144\n",
            "Epoch 878/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0131 - val_loss: 0.0147\n",
            "Epoch 879/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0131 - val_loss: 0.0144\n",
            "Epoch 880/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0130 - val_loss: 0.0146\n",
            "Epoch 881/1000\n",
            "1600/1600 [==============================] - 0s 8us/step - loss: 0.0132 - val_loss: 0.0143\n",
            "Epoch 882/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0130 - val_loss: 0.0145\n",
            "Epoch 883/1000\n",
            "1600/1600 [==============================] - 0s 8us/step - loss: 0.0130 - val_loss: 0.0146\n",
            "Epoch 884/1000\n",
            "1600/1600 [==============================] - 0s 8us/step - loss: 0.0131 - val_loss: 0.0142\n",
            "Epoch 885/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0129 - val_loss: 0.0144\n",
            "Epoch 886/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0130 - val_loss: 0.0144\n",
            "Epoch 887/1000\n",
            "1600/1600 [==============================] - 0s 11us/step - loss: 0.0130 - val_loss: 0.0145\n",
            "Epoch 888/1000\n",
            "1600/1600 [==============================] - 0s 8us/step - loss: 0.0130 - val_loss: 0.0145\n",
            "Epoch 889/1000\n",
            "1600/1600 [==============================] - 0s 8us/step - loss: 0.0130 - val_loss: 0.0143\n",
            "Epoch 890/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0129 - val_loss: 0.0143\n",
            "Epoch 891/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0129 - val_loss: 0.0142\n",
            "Epoch 892/1000\n",
            "1600/1600 [==============================] - 0s 8us/step - loss: 0.0130 - val_loss: 0.0146\n",
            "Epoch 893/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0130 - val_loss: 0.0149\n",
            "Epoch 894/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0131 - val_loss: 0.0147\n",
            "Epoch 895/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0131 - val_loss: 0.0142\n",
            "Epoch 896/1000\n",
            "1600/1600 [==============================] - 0s 8us/step - loss: 0.0131 - val_loss: 0.0145\n",
            "Epoch 897/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0135 - val_loss: 0.0154\n",
            "Epoch 898/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0136 - val_loss: 0.0141\n",
            "Epoch 899/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0130 - val_loss: 0.0147\n",
            "Epoch 900/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0134 - val_loss: 0.0143\n",
            "Epoch 901/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0131 - val_loss: 0.0144\n",
            "Epoch 902/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0131 - val_loss: 0.0145\n",
            "Epoch 903/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0131 - val_loss: 0.0143\n",
            "Epoch 904/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0133 - val_loss: 0.0149\n",
            "Epoch 905/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0131 - val_loss: 0.0143\n",
            "Epoch 906/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0130 - val_loss: 0.0148\n",
            "Epoch 907/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0132 - val_loss: 0.0143\n",
            "Epoch 908/1000\n",
            "1600/1600 [==============================] - 0s 15us/step - loss: 0.0133 - val_loss: 0.0144\n",
            "Epoch 909/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0132 - val_loss: 0.0146\n",
            "Epoch 910/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0134 - val_loss: 0.0148\n",
            "Epoch 911/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0133 - val_loss: 0.0150\n",
            "Epoch 912/1000\n",
            "1600/1600 [==============================] - 0s 8us/step - loss: 0.0131 - val_loss: 0.0143\n",
            "Epoch 913/1000\n",
            "1600/1600 [==============================] - 0s 8us/step - loss: 0.0132 - val_loss: 0.0144\n",
            "Epoch 914/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0130 - val_loss: 0.0142\n",
            "Epoch 915/1000\n",
            "1600/1600 [==============================] - 0s 11us/step - loss: 0.0133 - val_loss: 0.0150\n",
            "Epoch 916/1000\n",
            "1600/1600 [==============================] - 0s 11us/step - loss: 0.0131 - val_loss: 0.0146\n",
            "Epoch 917/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0134 - val_loss: 0.0145\n",
            "Epoch 918/1000\n",
            "1600/1600 [==============================] - 0s 8us/step - loss: 0.0130 - val_loss: 0.0142\n",
            "Epoch 919/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0130 - val_loss: 0.0144\n",
            "Epoch 920/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0135 - val_loss: 0.0143\n",
            "Epoch 921/1000\n",
            "1600/1600 [==============================] - 0s 12us/step - loss: 0.0130 - val_loss: 0.0143\n",
            "Epoch 922/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0131 - val_loss: 0.0144\n",
            "Epoch 923/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0130 - val_loss: 0.0142\n",
            "Epoch 924/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0131 - val_loss: 0.0143\n",
            "Epoch 925/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0130 - val_loss: 0.0145\n",
            "Epoch 926/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0129 - val_loss: 0.0146\n",
            "Epoch 927/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0130 - val_loss: 0.0144\n",
            "Epoch 928/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0130 - val_loss: 0.0151\n",
            "Epoch 929/1000\n",
            "1600/1600 [==============================] - 0s 8us/step - loss: 0.0134 - val_loss: 0.0143\n",
            "Epoch 930/1000\n",
            "1600/1600 [==============================] - 0s 11us/step - loss: 0.0130 - val_loss: 0.0143\n",
            "Epoch 931/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0130 - val_loss: 0.0143\n",
            "Epoch 932/1000\n",
            "1600/1600 [==============================] - 0s 11us/step - loss: 0.0130 - val_loss: 0.0142\n",
            "Epoch 933/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0135 - val_loss: 0.0146\n",
            "Epoch 934/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0130 - val_loss: 0.0148\n",
            "Epoch 935/1000\n",
            "1600/1600 [==============================] - 0s 8us/step - loss: 0.0132 - val_loss: 0.0144\n",
            "Epoch 936/1000\n",
            "1600/1600 [==============================] - 0s 8us/step - loss: 0.0131 - val_loss: 0.0143\n",
            "Epoch 937/1000\n",
            "1600/1600 [==============================] - 0s 8us/step - loss: 0.0129 - val_loss: 0.0142\n",
            "Epoch 938/1000\n",
            "1600/1600 [==============================] - 0s 8us/step - loss: 0.0130 - val_loss: 0.0144\n",
            "Epoch 939/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0130 - val_loss: 0.0144\n",
            "Epoch 940/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0130 - val_loss: 0.0142\n",
            "Epoch 941/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0129 - val_loss: 0.0145\n",
            "Epoch 942/1000\n",
            "1600/1600 [==============================] - 0s 11us/step - loss: 0.0129 - val_loss: 0.0145\n",
            "Epoch 943/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0130 - val_loss: 0.0147\n",
            "Epoch 944/1000\n",
            "1600/1600 [==============================] - 0s 12us/step - loss: 0.0133 - val_loss: 0.0143\n",
            "Epoch 945/1000\n",
            "1600/1600 [==============================] - 0s 12us/step - loss: 0.0130 - val_loss: 0.0146\n",
            "Epoch 946/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0132 - val_loss: 0.0145\n",
            "Epoch 947/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0132 - val_loss: 0.0145\n",
            "Epoch 948/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0131 - val_loss: 0.0147\n",
            "Epoch 949/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0131 - val_loss: 0.0147\n",
            "Epoch 950/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0132 - val_loss: 0.0144\n",
            "Epoch 951/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0131 - val_loss: 0.0145\n",
            "Epoch 952/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0131 - val_loss: 0.0146\n",
            "Epoch 953/1000\n",
            "1600/1600 [==============================] - 0s 11us/step - loss: 0.0130 - val_loss: 0.0146\n",
            "Epoch 954/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0134 - val_loss: 0.0143\n",
            "Epoch 955/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0132 - val_loss: 0.0151\n",
            "Epoch 956/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0132 - val_loss: 0.0146\n",
            "Epoch 957/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0134 - val_loss: 0.0148\n",
            "Epoch 958/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0134 - val_loss: 0.0141\n",
            "Epoch 959/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0137 - val_loss: 0.0155\n",
            "Epoch 960/1000\n",
            "1600/1600 [==============================] - 0s 8us/step - loss: 0.0134 - val_loss: 0.0146\n",
            "Epoch 961/1000\n",
            "1600/1600 [==============================] - 0s 11us/step - loss: 0.0131 - val_loss: 0.0144\n",
            "Epoch 962/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0129 - val_loss: 0.0143\n",
            "Epoch 963/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0130 - val_loss: 0.0145\n",
            "Epoch 964/1000\n",
            "1600/1600 [==============================] - 0s 8us/step - loss: 0.0130 - val_loss: 0.0144\n",
            "Epoch 965/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0130 - val_loss: 0.0147\n",
            "Epoch 966/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0131 - val_loss: 0.0144\n",
            "Epoch 967/1000\n",
            "1600/1600 [==============================] - 0s 8us/step - loss: 0.0130 - val_loss: 0.0144\n",
            "Epoch 968/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0131 - val_loss: 0.0143\n",
            "Epoch 969/1000\n",
            "1600/1600 [==============================] - 0s 8us/step - loss: 0.0130 - val_loss: 0.0145\n",
            "Epoch 970/1000\n",
            "1600/1600 [==============================] - 0s 8us/step - loss: 0.0131 - val_loss: 0.0147\n",
            "Epoch 971/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0132 - val_loss: 0.0142\n",
            "Epoch 972/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0130 - val_loss: 0.0145\n",
            "Epoch 973/1000\n",
            "1600/1600 [==============================] - 0s 8us/step - loss: 0.0132 - val_loss: 0.0143\n",
            "Epoch 974/1000\n",
            "1600/1600 [==============================] - 0s 11us/step - loss: 0.0131 - val_loss: 0.0144\n",
            "Epoch 975/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0129 - val_loss: 0.0145\n",
            "Epoch 976/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0130 - val_loss: 0.0146\n",
            "Epoch 977/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0131 - val_loss: 0.0147\n",
            "Epoch 978/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0132 - val_loss: 0.0143\n",
            "Epoch 979/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0137 - val_loss: 0.0144\n",
            "Epoch 980/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0131 - val_loss: 0.0147\n",
            "Epoch 981/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0130 - val_loss: 0.0144\n",
            "Epoch 982/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0132 - val_loss: 0.0145\n",
            "Epoch 983/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0132 - val_loss: 0.0145\n",
            "Epoch 984/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0130 - val_loss: 0.0150\n",
            "Epoch 985/1000\n",
            "1600/1600 [==============================] - 0s 11us/step - loss: 0.0133 - val_loss: 0.0142\n",
            "Epoch 986/1000\n",
            "1600/1600 [==============================] - 0s 11us/step - loss: 0.0131 - val_loss: 0.0144\n",
            "Epoch 987/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0131 - val_loss: 0.0146\n",
            "Epoch 988/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0130 - val_loss: 0.0143\n",
            "Epoch 989/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0130 - val_loss: 0.0147\n",
            "Epoch 990/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0133 - val_loss: 0.0141\n",
            "Epoch 991/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0130 - val_loss: 0.0144\n",
            "Epoch 992/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0130 - val_loss: 0.0146\n",
            "Epoch 993/1000\n",
            "1600/1600 [==============================] - 0s 8us/step - loss: 0.0130 - val_loss: 0.0145\n",
            "Epoch 994/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0129 - val_loss: 0.0142\n",
            "Epoch 995/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0130 - val_loss: 0.0143\n",
            "Epoch 996/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0129 - val_loss: 0.0145\n",
            "Epoch 997/1000\n",
            "1600/1600 [==============================] - 0s 8us/step - loss: 0.0129 - val_loss: 0.0144\n",
            "Epoch 998/1000\n",
            "1600/1600 [==============================] - 0s 10us/step - loss: 0.0131 - val_loss: 0.0145\n",
            "Epoch 999/1000\n",
            "1600/1600 [==============================] - 0s 9us/step - loss: 0.0130 - val_loss: 0.0143\n",
            "Epoch 1000/1000\n",
            "1600/1600 [==============================] - 0s 8us/step - loss: 0.0129 - val_loss: 0.0145\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd8f8937128>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FXmKzYT0ZNg0",
        "colab_type": "text"
      },
      "source": [
        "##Time for prediction!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VLUG0YO9ZUPb",
        "colab_type": "text"
      },
      "source": [
        "###Loading the test dataset.\n",
        "\n",
        "Also, scaling the datset with Standard Scaler."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTrzBku8D6E_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test = pd.read_csv('test_data.csv')\n",
        "\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(test[features])\n",
        "test_data = pd.DataFrame(scaler.transform(test[features]))\n",
        "test_data.columns = features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5OeRG8mGGVd",
        "colab_type": "code",
        "outputId": "75ed2da2-afdb-4c7e-b650-2d2054e75349",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "test_data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Avg_ping</th>\n",
              "      <th>Total_travel_dist</th>\n",
              "      <th>Avg_Srv_time</th>\n",
              "      <th>Avg_firing_dist</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.633884</td>\n",
              "      <td>0.161292</td>\n",
              "      <td>0.533723</td>\n",
              "      <td>0.840465</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.099256</td>\n",
              "      <td>-1.569874</td>\n",
              "      <td>-0.823939</td>\n",
              "      <td>-0.158796</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-1.442217</td>\n",
              "      <td>0.252750</td>\n",
              "      <td>-0.442176</td>\n",
              "      <td>0.294310</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.569217</td>\n",
              "      <td>0.793513</td>\n",
              "      <td>-0.917484</td>\n",
              "      <td>-0.903185</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.057977</td>\n",
              "      <td>0.690442</td>\n",
              "      <td>0.159544</td>\n",
              "      <td>-0.292301</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Avg_ping  Total_travel_dist  Avg_Srv_time  Avg_firing_dist\n",
              "0 -0.633884           0.161292      0.533723         0.840465\n",
              "1  0.099256          -1.569874     -0.823939        -0.158796\n",
              "2 -1.442217           0.252750     -0.442176         0.294310\n",
              "3  0.569217           0.793513     -0.917484        -0.903185\n",
              "4  1.057977           0.690442      0.159544        -0.292301"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KmTLpexPZk36",
        "colab_type": "text"
      },
      "source": [
        "###Predicting the result."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FxNuMnumGIVM",
        "colab_type": "code",
        "outputId": "c787d18e-2e08-40ef-a165-ac34e6fb9cdc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3417
        }
      },
      "source": [
        "result = nn.predict(test_data) * 1000\n",
        "result"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1762.2316],\n",
              "       [1847.3726],\n",
              "       [1792.4703],\n",
              "       [1887.4484],\n",
              "       [1823.2941],\n",
              "       [1760.1783],\n",
              "       [1745.0029],\n",
              "       [1942.3347],\n",
              "       [1723.3568],\n",
              "       [1777.0928],\n",
              "       [1781.4883],\n",
              "       [1886.7306],\n",
              "       [1875.561 ],\n",
              "       [1745.2429],\n",
              "       [1750.7045],\n",
              "       [1734.6979],\n",
              "       [1771.5371],\n",
              "       [1838.7068],\n",
              "       [1783.1173],\n",
              "       [1882.4216],\n",
              "       [1823.7384],\n",
              "       [1949.121 ],\n",
              "       [1760.2009],\n",
              "       [1767.802 ],\n",
              "       [1717.9905],\n",
              "       [1835.9469],\n",
              "       [1902.9534],\n",
              "       [1912.2959],\n",
              "       [1772.9922],\n",
              "       [1801.7332],\n",
              "       [1878.0509],\n",
              "       [1860.1066],\n",
              "       [1950.1287],\n",
              "       [1829.1453],\n",
              "       [1943.4237],\n",
              "       [1850.1597],\n",
              "       [1959.9006],\n",
              "       [1817.5398],\n",
              "       [1852.3729],\n",
              "       [1776.087 ],\n",
              "       [1719.5265],\n",
              "       [1786.2865],\n",
              "       [1896.1229],\n",
              "       [1730.9076],\n",
              "       [1896.5917],\n",
              "       [1749.0459],\n",
              "       [1747.9425],\n",
              "       [1739.3842],\n",
              "       [1804.0796],\n",
              "       [1925.6002],\n",
              "       [1930.8406],\n",
              "       [1802.1006],\n",
              "       [1908.0581],\n",
              "       [1917.8591],\n",
              "       [1729.0084],\n",
              "       [1919.6947],\n",
              "       [1812.5363],\n",
              "       [1775.1561],\n",
              "       [1910.513 ],\n",
              "       [1806.4518],\n",
              "       [1852.5111],\n",
              "       [1787.4452],\n",
              "       [1873.8066],\n",
              "       [1735.8917],\n",
              "       [1844.6199],\n",
              "       [1765.4137],\n",
              "       [1762.5157],\n",
              "       [1923.444 ],\n",
              "       [1939.1152],\n",
              "       [1813.112 ],\n",
              "       [1810.8232],\n",
              "       [1754.6152],\n",
              "       [1875.8813],\n",
              "       [1729.1853],\n",
              "       [1801.2734],\n",
              "       [1802.2628],\n",
              "       [1834.6406],\n",
              "       [1880.1239],\n",
              "       [1794.5198],\n",
              "       [1758.0702],\n",
              "       [1911.3503],\n",
              "       [1766.359 ],\n",
              "       [1935.3009],\n",
              "       [1912.7029],\n",
              "       [1813.2933],\n",
              "       [1923.4518],\n",
              "       [1839.4457],\n",
              "       [1760.0564],\n",
              "       [1804.6613],\n",
              "       [1918.1519],\n",
              "       [1906.5806],\n",
              "       [1782.7208],\n",
              "       [1853.5625],\n",
              "       [1937.8857],\n",
              "       [1764.877 ],\n",
              "       [1880.8964],\n",
              "       [1754.8234],\n",
              "       [1732.0829],\n",
              "       [1926.1681],\n",
              "       [1920.673 ],\n",
              "       [1793.6992],\n",
              "       [1844.4089],\n",
              "       [1780.6403],\n",
              "       [1729.0625],\n",
              "       [1838.7834],\n",
              "       [1735.2458],\n",
              "       [1728.0433],\n",
              "       [1808.4725],\n",
              "       [1877.3524],\n",
              "       [1946.3064],\n",
              "       [1830.63  ],\n",
              "       [1735.5016],\n",
              "       [1875.1638],\n",
              "       [1869.1675],\n",
              "       [1730.3301],\n",
              "       [1781.567 ],\n",
              "       [1749.5773],\n",
              "       [1763.763 ],\n",
              "       [1868.8291],\n",
              "       [1790.2379],\n",
              "       [1791.0969],\n",
              "       [1800.8054],\n",
              "       [1922.1427],\n",
              "       [1763.9077],\n",
              "       [1758.9559],\n",
              "       [1883.637 ],\n",
              "       [1741.4008],\n",
              "       [1792.6278],\n",
              "       [1973.4308],\n",
              "       [1801.9252],\n",
              "       [1858.7184],\n",
              "       [1898.7896],\n",
              "       [1899.41  ],\n",
              "       [1722.3198],\n",
              "       [1763.7338],\n",
              "       [1728.8167],\n",
              "       [1954.483 ],\n",
              "       [1828.5142],\n",
              "       [1931.0349],\n",
              "       [1778.0276],\n",
              "       [1865.5107],\n",
              "       [1770.1265],\n",
              "       [1962.8386],\n",
              "       [1744.0787],\n",
              "       [1843.8904],\n",
              "       [1746.6042],\n",
              "       [1881.8612],\n",
              "       [1763.1542],\n",
              "       [1739.9541],\n",
              "       [1739.7125],\n",
              "       [1929.7701],\n",
              "       [1755.701 ],\n",
              "       [1846.8145],\n",
              "       [1748.6715],\n",
              "       [1788.6046],\n",
              "       [1853.129 ],\n",
              "       [1744.6956],\n",
              "       [1760.4247],\n",
              "       [1791.0918],\n",
              "       [1755.1703],\n",
              "       [1751.6876],\n",
              "       [1935.7518],\n",
              "       [1762.735 ],\n",
              "       [1794.3402],\n",
              "       [1866.3789],\n",
              "       [1869.1709],\n",
              "       [1919.1526],\n",
              "       [1852.8688],\n",
              "       [1732.7788],\n",
              "       [1816.4893],\n",
              "       [1754.8027],\n",
              "       [1751.3197],\n",
              "       [1939.7684],\n",
              "       [1870.6277],\n",
              "       [1788.5824],\n",
              "       [1885.0002],\n",
              "       [1868.1136],\n",
              "       [1779.7206],\n",
              "       [1926.5653],\n",
              "       [1928.5842],\n",
              "       [1728.9083],\n",
              "       [1730.6012],\n",
              "       [1765.4233],\n",
              "       [1756.6499],\n",
              "       [1848.0352],\n",
              "       [1804.908 ],\n",
              "       [1753.8713],\n",
              "       [1725.1626],\n",
              "       [1931.146 ],\n",
              "       [1792.2452],\n",
              "       [1772.7612],\n",
              "       [1758.543 ],\n",
              "       [1722.0713],\n",
              "       [1738.7773],\n",
              "       [1880.8368],\n",
              "       [1820.4304],\n",
              "       [1898.2167],\n",
              "       [1830.5608],\n",
              "       [1730.9128],\n",
              "       [1933.1302]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBTx_x8MPD4z",
        "colab_type": "code",
        "outputId": "9f5bf681-72a3-499c-a32f-7cbc7051b651",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(result)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "200"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lwPlxAtCZvJf",
        "colab_type": "text"
      },
      "source": [
        "##Creating the output file for submission"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sRlL-OUgI14i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "np.savetxt(\"submission.csv\", result, fmt='%s')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}